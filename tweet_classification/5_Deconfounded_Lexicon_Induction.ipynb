{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import Sequential, backend, regularizers\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, Flatten, Conv1D, MaxPooling1D\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import keras.backend\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load tweet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for importing & cleaning relevant tweets\n",
    "def lower(s):\n",
    "    return s.lower()\n",
    "\n",
    "def tweet_imports(filename):\n",
    "    imp = pd.read_pickle(filename)\n",
    "    imp = imp.drop_duplicates()\n",
    "    imp['tweet_clean'] = imp['tweet'].str.replace('http\\S+|www.\\S+|pic.twitter.com\\S+', '', case=False)\n",
    "    imp['tweet_clean'] =imp['tweet_clean'].replace('[^A-Za-z0-9 ]+','',regex=True)\n",
    "    imp['tweet_clean'] = imp['tweet_clean'].apply(lower)#map(lambda x: x.lower(), imp['tweet_clean'])\n",
    "    imp['date'] = pd.to_datetime(imp['date'])\n",
    "    return imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_affirm_tweets = tweet_imports('all_affirm_tweets.pkl')\n",
    "cleaned_deny_tweets = tweet_imports('all_deny_tweets.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>tweet</th>\n",
       "      <th>mentions</th>\n",
       "      <th>replies_count</th>\n",
       "      <th>retweets_count</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>username</th>\n",
       "      <th>search_term</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1177060829901885441</td>\n",
       "      <td>2019-09-25</td>\n",
       "      <td>20:22:25</td>\n",
       "      <td>#IPCC just released the #SROCC - a new report ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>75</td>\n",
       "      <td>['#ipcc', '#srocc']</td>\n",
       "      <td>350</td>\n",
       "      <td>ice</td>\n",
       "      <td>1</td>\n",
       "      <td>ipcc just released the srocc  a new report on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1176786922687148032</td>\n",
       "      <td>2019-09-25</td>\n",
       "      <td>02:14:00</td>\n",
       "      <td>The #IPCC special report on ocean and ice is o...</td>\n",
       "      <td>[]</td>\n",
       "      <td>5</td>\n",
       "      <td>83</td>\n",
       "      <td>112</td>\n",
       "      <td>['#ipcc', '#srocc']</td>\n",
       "      <td>350</td>\n",
       "      <td>ice</td>\n",
       "      <td>1</td>\n",
       "      <td>the ipcc special report on ocean and ice is ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1164031877910618114</td>\n",
       "      <td>2019-08-20</td>\n",
       "      <td>21:30:01</td>\n",
       "      <td>Unusually warm water surrounding one of the la...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>93</td>\n",
       "      <td>[]</td>\n",
       "      <td>350</td>\n",
       "      <td>ice</td>\n",
       "      <td>1</td>\n",
       "      <td>unusually warm water surrounding one of the la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1152577659710427136</td>\n",
       "      <td>2019-07-20</td>\n",
       "      <td>06:55:02</td>\n",
       "      <td>This is one of the hottest summers on record. ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>26</td>\n",
       "      <td>['#abolishice']</td>\n",
       "      <td>350</td>\n",
       "      <td>ice</td>\n",
       "      <td>1</td>\n",
       "      <td>this is one of the hottest summers on record t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1146328119336460288</td>\n",
       "      <td>2019-07-03</td>\n",
       "      <td>01:01:36</td>\n",
       "      <td>Antarctic ice has taken a nosedive.\\n\\nThe amo...</td>\n",
       "      <td>[]</td>\n",
       "      <td>6</td>\n",
       "      <td>106</td>\n",
       "      <td>115</td>\n",
       "      <td>[]</td>\n",
       "      <td>350</td>\n",
       "      <td>ice</td>\n",
       "      <td>1</td>\n",
       "      <td>antarctic ice has taken a nosedivethe amount o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id       date      time  \\\n",
       "0  1177060829901885441 2019-09-25  20:22:25   \n",
       "1  1176786922687148032 2019-09-25  02:14:00   \n",
       "2  1164031877910618114 2019-08-20  21:30:01   \n",
       "3  1152577659710427136 2019-07-20  06:55:02   \n",
       "4  1146328119336460288 2019-07-03  01:01:36   \n",
       "\n",
       "                                               tweet mentions  replies_count  \\\n",
       "0  #IPCC just released the #SROCC - a new report ...       []              1   \n",
       "1  The #IPCC special report on ocean and ice is o...       []              5   \n",
       "2  Unusually warm water surrounding one of the la...       []              1   \n",
       "3  This is one of the hottest summers on record. ...       []              0   \n",
       "4  Antarctic ice has taken a nosedive.\\n\\nThe amo...       []              6   \n",
       "\n",
       "   retweets_count  likes_count             hashtags username search_term  \\\n",
       "0              40           75  ['#ipcc', '#srocc']      350         ice   \n",
       "1              83          112  ['#ipcc', '#srocc']      350         ice   \n",
       "2              62           93                   []      350         ice   \n",
       "3              17           26      ['#abolishice']      350         ice   \n",
       "4             106          115                   []      350         ice   \n",
       "\n",
       "   label                                        tweet_clean  \n",
       "0      1  ipcc just released the srocc  a new report on ...  \n",
       "1      1  the ipcc special report on ocean and ice is ou...  \n",
       "2      1  unusually warm water surrounding one of the la...  \n",
       "3      1  this is one of the hottest summers on record t...  \n",
       "4      1  antarctic ice has taken a nosedivethe amount o...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_affirm_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "230802"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_affirm_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290084"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_deny_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "# with open('generated.tsv','w') as f:\n",
    "#     csvwriter = csv.writer(f,delimiter='\\t')\n",
    "#     for ix in range(100):#len(cleaned_deny_tweets)):\n",
    "#         df_row = cleaned_deny_tweets.iloc[ix]\n",
    "#         csvwriter.writerow([df_row['tweet_clean'],float(df_row['likes_count']),\n",
    "#                                   float(df_row['retweets_count']),float(df_row['replies_count']),\n",
    "#                             df_row['username']])\n",
    "#     for ix in range(100):#len(cleaned_deny_tweets)):\n",
    "#         df_row = cleaned_deny_tweets.iloc[-ix]\n",
    "#         csvwriter.writerow([df_row['tweet_clean'],float(df_row['likes_count']),\n",
    "#                                   float(df_row['retweets_count']),float(df_row['replies_count']),\n",
    "#                             df_row['username']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('generated_affirm.tsv','w') as f:\n",
    "    csvwriter = csv.writer(f,delimiter='\\t')\n",
    "    for ix in range(100):#len(cleaned_deny_tweets)):\n",
    "        df_row = cleaned_affirm_tweets.iloc[ix]\n",
    "        csvwriter.writerow([df_row['tweet_clean'],float(df_row['likes_count']),\n",
    "                                  float(df_row['retweets_count']),float(df_row['replies_count']),\n",
    "                            df_row['username']])\n",
    "    for ix in range(100):#len(cleaned_deny_tweets)):\n",
    "        df_row = cleaned_affirm_tweets.iloc[-ix]\n",
    "        csvwriter.writerow([df_row['tweet_clean'],float(df_row['likes_count']),\n",
    "                                  float(df_row['retweets_count']),float(df_row['replies_count']),\n",
    "                            df_row['username']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
