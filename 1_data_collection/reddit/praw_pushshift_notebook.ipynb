{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import praw\n",
    "from praw.models import Submission\n",
    "from prawcore.exceptions import Forbidden,NotFound\n",
    "#from psaw import PushshiftAPI\n",
    "from pmaw import PushshiftAPI\n",
    "import csv\n",
    "import os\n",
    "from urllib.error import HTTPError\n",
    "import glob\n",
    "import requests\n",
    "import json\n",
    "from json import JSONDecodeError\n",
    "import datetime\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "_RE_COMBINE_WHITESPACE = re.compile(r\"\\s+\")\n",
    "\n",
    "def strip_whitespace(text):\n",
    "    return _RE_COMBINE_WHITESPACE.sub(\" \", text).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../keywords_high_precision.txt','r') as f:\n",
    "    KEYWORDS_HI_PREC = f.read().splitlines()\n",
    "\n",
    "KEYWORDS_SHORT = set([\"climate change\",\"global warming\",\"carbon\",\"co2\",\"methane\",\n",
    "                  \"green\",\"environment\",\"fossil fuel\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['global warming',\n",
       " 'climate change',\n",
       " 'carbon dioxide',\n",
       " 'co2',\n",
       " 'methane',\n",
       " 'fossil fuel',\n",
       " 'climate crisis',\n",
       " 'climate emergency',\n",
       " 'extreme weather',\n",
       " 'clean energy',\n",
       " 'renewable energy',\n",
       " 'cap and trade',\n",
       " 'sea level rise',\n",
       " 'IPCC',\n",
       " 'deforestation',\n",
       " 'permafrost',\n",
       " 'greenhouse gas',\n",
       " 'greenhouse effect',\n",
       " 'green new deal',\n",
       " 'environmentalism',\n",
       " 'EPA']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KEYWORDS_HI_PREC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways of getting Reddit data illustrated in this notebook:\n",
    "* 1. [PRAW (Python Reddit API Wrapper)](#https://praw.readthedocs.io/en/latest/)\n",
    "* 2. [Pushshift API](#https://pushshift.io/api-parameters/)\n",
    "    \n",
    "The main advantage of Pushshift is that it accesses data from an archive, so even posts from currently banned subreddits (e.g., r/The_Donald) are accessible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Using PRAW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "You need to first create a reddit instance to use the PRAW API. Fill in the 3 fields (left blank) according to the instructions [here](#https://praw.readthedocs.io/en/latest/getting_started/authentication.html). Note: you will need to have a Reddit account and to register a developer app [here](#https://www.reddit.com/prefs/apps/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id='ACEORGSlEeJyQhPyNRAUiA',\n",
    "                     client_secret='xGN33fztXu_4jiOek_RHUtMGhHXAcQ',\n",
    "                     user_agent='me',\n",
    "                    password='redditC0bintr@sena',\n",
    "                    username='Western-Wishbone573')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Western-Wishbone573\n"
     ]
    }
   ],
   "source": [
    "print(reddit.user.me())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Replace with the subreddits you're interested in\n",
    "non_niche_subs = set(['AskReddit','environment','politics','worldnews','climateskeptics',\n",
    "                     'Showerthoughts','climate','askscience','The_Donald','science','EcoInternet',\n",
    "                     'collapse','explainlikeimfive','conspiracy','NoStupidQuestions','australia',\n",
    "                     'unpopularopinion','climatechange','news','energy','canada','Conservative',\n",
    "                     'skeptic','todayilearned','shittyaskscience','ChapoTrapHouse','CanadaPolitics',\n",
    "                     'EverythingScience','worldpolitics','europe','AskScienceDiscussion',\n",
    "                     'ClimateOffensive','changemyview','ClimateActionPlan','AskTrumpSupporters',\n",
    "                     'GlobalWarming','GlobalClimateChange','esist','Green'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [
     0,
     53
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_praw_submissions(reddit_instance,subreddit_str):\n",
    "    \n",
    "    if not os.path.exists('praw_output'):\n",
    "        os.mkdir('praw_output')\n",
    "    \n",
    "    subreddit = reddit_instance.subreddit(subreddit_str)\n",
    "    print('Getting submissions and comments from: {} ...'.format(subreddit.display_name))  \n",
    "    try:\n",
    "        title = subreddit.title\n",
    "        desc = subreddit.description\n",
    "\n",
    "        if not os.path.exists('subreddits.tsv'):\n",
    "            with open('subreddits.tsv','w') as f:\n",
    "                csvwriter = csv.writer(f, delimiter='\\t')\n",
    "                csvwriter.writerow([subreddit.display_name,title,desc])\n",
    "        else:\n",
    "            with open('subreddits.tsv','a') as f:\n",
    "                csvwriter = csv.writer(f, delimiter='\\t')\n",
    "                csvwriter.writerow([subreddit.display_name,title,desc])\n",
    "\n",
    "        # Write header\n",
    "        with open(os.path.join('praw_output','{}.tsv'.format(subreddit.display_name)), 'w', newline='\\n') as csvfile:\n",
    "            csvwriter = csv.writer(csvfile, delimiter='\\t',\n",
    "                                    quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "            csvwriter.writerow(['title','author','date','is_video','id','num_downs','num_ups','upvote_ratio',\n",
    "                               'num_comments','score','text','subreddit'])\n",
    "\n",
    "        # Write body\n",
    "        for submission in subreddit.new(limit=None):\n",
    "            sub_title = submission.title\n",
    "            sub_author = submission.author.name if submission.author is not None else -1\n",
    "            sub_date = submission.created\n",
    "            sub_is_vid = submission.is_video\n",
    "            sub_id = submission.id\n",
    "            sub_downvotes = submission.downs\n",
    "            sub_upvotes = submission.ups\n",
    "            sub_upvote_ratio = submission.upvote_ratio\n",
    "            sub_num_comments = submission.num_comments\n",
    "            sub_score = submission.score\n",
    "            sub_text = submission.selftext.strip().replace('\\t','').replace('\\n','')\n",
    "            sub_subreddit = submission.subreddit.display_name\n",
    "            with open(os.path.join('praw_output','{}.tsv'.format(subreddit.display_name)), 'a', newline='\\n') as csvfile:\n",
    "                csvwriter = csv.writer(csvfile, delimiter='\\t',\n",
    "                                    quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "                csvwriter.writerow([sub_title,sub_author,sub_date,sub_is_vid,sub_id,sub_downvotes,\n",
    "                                   sub_upvotes,sub_upvote_ratio,sub_num_comments,sub_score,sub_text,sub_subreddit])\n",
    "        \n",
    "        print('Wrote output to:', os.path.join('praw_output','{}.tsv'.format(subreddit.display_name)))\n",
    "        \n",
    "    except HTTPError as e:\n",
    "        if e.code == 403:\n",
    "            print('Forbidden: private subreddit.')\n",
    "            \n",
    "def get_praw_submission_comments(reddit_instance,subreddit,submission_id):\n",
    "    \n",
    "    submission = Submission(reddit_instance,id=submission_id)\n",
    "    \n",
    "    try:\n",
    "        submission.comments.replace_more(limit=0)\n",
    "        all_comments = submission.comments.list()\n",
    "\n",
    "        # Write header\n",
    "        with open(os.path.join('praw_output','post_comments','{}_COMMENTS.tsv'.format(subreddit)), 'w', newline='\\n') as csvfile:\n",
    "            csvwriter = csv.writer(csvfile, delimiter='\\t',\n",
    "                                    quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "            csvwriter.writerow(['submission_id','author','text','date','id','controversiality','num_downs','num_ups',\n",
    "                               'num_likes','score','subreddit'])\n",
    "\n",
    "        # Write body\n",
    "        for comment in all_comments:\n",
    "            sub_id = comment._submission.id\n",
    "            assert sub_id == submission_id\n",
    "            author_name = comment.author.name if comment.author is not None else -1\n",
    "            comment_body = comment.body.strip().replace('\\t','').replace('\\n','')\n",
    "            date_created = comment.created\n",
    "            comment_id = comment.id\n",
    "            controversiality = comment.controversiality\n",
    "            num_downs = comment.downs\n",
    "            num_ups = comment.ups\n",
    "            num_likes = comment.likes\n",
    "            score = comment.score\n",
    "            subreddit_name = comment.subreddit.display_name\n",
    "            #print(subreddit_name,subreddit)\n",
    "            assert subreddit_name == subreddit\n",
    "            \n",
    "            with open(os.path.join('praw_output','post_comments','{}_COMMENTS.tsv'.format(subreddit_name)), 'a', newline='\\n') as csvfile:\n",
    "                csvwriter = csv.writer(csvfile, delimiter='\\t',\n",
    "                                    quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "                csvwriter.writerow([sub_id,author_name,comment_body,date_created,comment_id,controversiality,\n",
    "                                   num_downs,num_ups,num_likes,score,subreddit_name])\n",
    "    except HTTPError as e:\n",
    "        if e.code == 403:\n",
    "            print('Forbidden: private subreddit.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Get a post by its post id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "p_id = '2yrvob'\n",
    "post = reddit.submission(id=p_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#[x.split('_')[-1] for x in post.__dict__['_comments_by_id'].keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://www.sciencedaily.com/releases/2010/01/100114081543.htm'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post.is_self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[deleted]'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post.selftext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Get posts from a subreddit (e.g. r/spambotwatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting submissions and comments from: spambotwatch ...\n",
      "Wrote output to: praw_output/spambotwatch.tsv\n"
     ]
    }
   ],
   "source": [
    "get_praw_submissions(reddit,'spambotwatch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>is_video</th>\n",
       "      <th>id</th>\n",
       "      <th>num_downs</th>\n",
       "      <th>num_ups</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>text</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JEEVAN BOBY (u/jeevanbobyvallickad) - Reddit</td>\n",
       "      <td>TheGeorge</td>\n",
       "      <td>1.566348e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>ct1svp</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>spambotwatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>overview for funnynova</td>\n",
       "      <td>BuckRowdy</td>\n",
       "      <td>1.555999e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>bg7w8w</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>spambotwatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spams Dating Tips Websites all with Stolen Con...</td>\n",
       "      <td>TheGeorge</td>\n",
       "      <td>1.554842e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>bb7e57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>spambotwatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>overview for poopcake5</td>\n",
       "      <td>ActionScripter9109</td>\n",
       "      <td>1.501372e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>6qbmgl</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>spambotwatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>overview for sutei_m</td>\n",
       "      <td>ActionScripter9109</td>\n",
       "      <td>1.501372e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>6qbmar</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>spambotwatch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title              author  \\\n",
       "0       JEEVAN BOBY (u/jeevanbobyvallickad) - Reddit           TheGeorge   \n",
       "1                             overview for funnynova           BuckRowdy   \n",
       "2  Spams Dating Tips Websites all with Stolen Con...           TheGeorge   \n",
       "3                             overview for poopcake5  ActionScripter9109   \n",
       "4                               overview for sutei_m  ActionScripter9109   \n",
       "\n",
       "           date  is_video      id  num_downs  num_ups  upvote_ratio  \\\n",
       "0  1.566348e+09     False  ct1svp          0        1           1.0   \n",
       "1  1.555999e+09     False  bg7w8w          0        1           1.0   \n",
       "2  1.554842e+09     False  bb7e57          0        1           1.0   \n",
       "3  1.501372e+09     False  6qbmgl          0        1           1.0   \n",
       "4  1.501372e+09     False  6qbmar          0        1           1.0   \n",
       "\n",
       "   num_comments  score  text     subreddit  \n",
       "0             1      1   NaN  spambotwatch  \n",
       "1             0      1   NaN  spambotwatch  \n",
       "2             0      1   NaN  spambotwatch  \n",
       "3             1      1   NaN  spambotwatch  \n",
       "4             1      1   NaN  spambotwatch  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spambotwatch_df = pd.read_csv('praw_output/spambotwatch.tsv',sep='\\t',header=0)\n",
    "spambotwatch_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Get posts from list of subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for sub in non_niche_subs:\n",
    "    get_submissions(reddit,sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Inspect output: tsv of subreddits and meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>climateskeptics</td>\n",
       "      <td>Climate Skeptics: Trying to see through the al...</td>\n",
       "      <td>Seeing past hyperbole, alarmism and environmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>skeptic</td>\n",
       "      <td>skeptic</td>\n",
       "      <td>## [Click this link to Read the Rules](http://...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>climatechange</td>\n",
       "      <td>A place for a rational discussion on a divisiv...</td>\n",
       "      <td>This is a place for the rational discussion of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>climate</td>\n",
       "      <td>Information about the world's climate</td>\n",
       "      <td>Real and accurate data about the Earth's clima...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>science</td>\n",
       "      <td>Reddit Science</td>\n",
       "      <td># [Submission Rules](https://www.reddit.com/r/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>republicans</td>\n",
       "      <td>Republicans - RNC - GOP: Grand Old Party</td>\n",
       "      <td>Republican, RNC and GOP news, issues, gossip, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>askaconservative</td>\n",
       "      <td>Ask A Conservative: Ask Conservatives And Repu...</td>\n",
       "      <td>#[Ask a Conservative](/r/askaconservative)\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Conservative</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>#####\\n**[Join us on discord.](https://discord...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>conservatives</td>\n",
       "      <td>conservatives</td>\n",
       "      <td>Conservatism (from, conservare, \"to preserve\")...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>AskTrumpSupporters</td>\n",
       "      <td>AskTrumpSupporters</td>\n",
       "      <td>#We are not a typical subreddit. Read the [ful...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0                                                  1  \\\n",
       "0      climateskeptics  Climate Skeptics: Trying to see through the al...   \n",
       "1              skeptic                                            skeptic   \n",
       "2        climatechange  A place for a rational discussion on a divisiv...   \n",
       "3              climate              Information about the world's climate   \n",
       "4              science                                     Reddit Science   \n",
       "..                 ...                                                ...   \n",
       "63         republicans           Republicans - RNC - GOP: Grand Old Party   \n",
       "64    askaconservative  Ask A Conservative: Ask Conservatives And Repu...   \n",
       "65        Conservative                                       Conservative   \n",
       "66       conservatives                                      conservatives   \n",
       "67  AskTrumpSupporters                                 AskTrumpSupporters   \n",
       "\n",
       "                                                    2  \n",
       "0   Seeing past hyperbole, alarmism and environmen...  \n",
       "1   ## [Click this link to Read the Rules](http://...  \n",
       "2   This is a place for the rational discussion of...  \n",
       "3   Real and accurate data about the Earth's clima...  \n",
       "4   # [Submission Rules](https://www.reddit.com/r/...  \n",
       "..                                                ...  \n",
       "63  Republican, RNC and GOP news, issues, gossip, ...  \n",
       "64  #[Ask a Conservative](/r/askaconservative)\\n\\n...  \n",
       "65  #####\\n**[Join us on discord.](https://discord...  \n",
       "66  Conservatism (from, conservare, \"to preserve\")...  \n",
       "67  #We are not a typical subreddit. Read the [ful...  \n",
       "\n",
       "[68 rows x 3 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('subreddits.tsv',sep='\\t',header=None).drop_duplicates(0,keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Inspect output: tsv of one subreddit's posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('praw_output/350.tsv',sep='\\t',header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'author', 'date', 'is_video', 'id', 'num_downs', 'num_ups',\n",
       "       'upvote_ratio', 'num_comments', 'score', 'text', 'subreddit'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    127\n",
       "Name: is_video, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.is_video.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350    127\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.subreddit.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Get comments for all posts with non-zero num comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "code_folding": [
     1
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already got comments for subreddit praw_output/posts/350.tsv\n",
      "Already got comments for subreddit praw_output/posts/350ppm.tsv\n",
      "Already got comments for subreddit praw_output/posts/askaconservative.tsv\n",
      "Already got comments for subreddit praw_output/posts/AskTrumpSupporters.tsv\n",
      "Already got comments for subreddit praw_output/posts/carboncapture.tsv\n",
      "Already got comments for subreddit praw_output/posts/carbontax.tsv\n",
      "Already got comments for subreddit praw_output/posts/ccfunding.tsv\n",
      "Already got comments for subreddit praw_output/posts/climate.tsv\n",
      "Already got comments for subreddit praw_output/posts/climate_activism.tsv\n",
      "Already got comments for subreddit praw_output/posts/climate_discussion.tsv\n",
      "Already got comments for subreddit praw_output/posts/climate_science.tsv\n",
      "Already got comments for subreddit praw_output/posts/ClimateActionPlan.tsv\n",
      "Already got comments for subreddit praw_output/posts/climatechange.tsv\n",
      "Already got comments for subreddit praw_output/posts/ClimateChangeCancer.tsv\n",
      "Already got comments for subreddit praw_output/posts/climatecmv.tsv\n",
      "Already got comments for subreddit praw_output/posts/ClimateCrisis.tsv\n",
      "Already got comments for subreddit praw_output/posts/climatedebate.tsv\n",
      "Already got comments for subreddit praw_output/posts/climatedebate2.tsv\n",
      "Already got comments for subreddit praw_output/posts/climategate.tsv\n",
      "0 comments among all posts in subreddit: ClimateMobilization\n",
      "Already got comments for subreddit praw_output/posts/ClimateOffensive.tsv\n",
      "Already got comments for subreddit praw_output/posts/climatepredicts.tsv\n",
      "Already got comments for subreddit praw_output/posts/ClimatePreparation.tsv\n",
      "Already got comments for subreddit praw_output/posts/climatesecurity.tsv\n",
      "Already got comments for subreddit praw_output/posts/climateskeptics.tsv\n",
      "Already got comments for subreddit praw_output/posts/ClimateSkepticScience.tsv\n",
      "Already got comments for subreddit praw_output/posts/ClimateSplattergate.tsv\n",
      "0 comments among all posts in subreddit: climatestasis\n",
      "Already got comments for subreddit praw_output/posts/Climatology.tsv\n",
      "Already got comments for subreddit praw_output/posts/climatskeptics.tsv\n",
      "Already got comments for subreddit praw_output/posts/CollapseSurvival.tsv\n",
      "Already got comments for subreddit praw_output/posts/conservation.tsv\n",
      "Already got comments for subreddit praw_output/posts/Conservative.tsv\n",
      "Already got comments for subreddit praw_output/posts/conservatives.tsv\n",
      "Subreddit praw_output/posts/DebateAClimateSkeptic.tsv has no posts\n",
      "Getting comments from posts in subreddit: deep_ecology\n",
      "Getting comments from posts in subreddit: drought\n",
      "Getting comments from posts in subreddit: EarthDisaster\n",
      "Getting comments from posts in subreddit: EarthScience\n",
      "Getting comments from posts in subreddit: EcoInternet\n",
      "Getting comments from posts in subreddit: ecology\n",
      "Subreddit praw_output/posts/ecologycenter.tsv has no posts\n",
      "Getting comments from posts in subreddit: EcoRestoration\n",
      "Getting comments from posts in subreddit: energy\n",
      "Getting comments from posts in subreddit: enviroaction\n",
      "Getting comments from posts in subreddit: Enviroment\n",
      "Getting comments from posts in subreddit: environment\n",
      "Getting comments from posts in subreddit: environmental_science\n",
      "Subreddit praw_output/posts/Global_Warming.tsv has no posts\n",
      "Getting comments from posts in subreddit: GlobalClimateChange\n",
      "Getting comments from posts in subreddit: GlobalWarming\n",
      "Getting comments from posts in subreddit: GlobalWarmingisBunk\n",
      "Getting comments from posts in subreddit: Green\n",
      "Getting comments from posts in subreddit: GreenNewIdeas\n",
      "0 comments among all posts in subreddit: GreenPlanet\n",
      "0 comments among all posts in subreddit: GWB\n",
      "Getting comments from posts in subreddit: Rainforest\n",
      "Subreddit praw_output/posts/RealClimateSkeptics.tsv has no posts\n",
      "Getting comments from posts in subreddit: Republican\n",
      "Getting comments from posts in subreddit: republicans\n",
      "Getting comments from posts in subreddit: Restoration_Ecology\n",
      "Getting comments from posts in subreddit: science\n",
      "Getting comments from posts in subreddit: skeptic\n",
      "Getting comments from posts in subreddit: sustainability\n",
      "Getting comments from posts in subreddit: Sustainable_Energy\n",
      "Subreddit praw_output/posts/ThunbergSyndrome.tsv has no posts\n",
      "Getting comments from posts in subreddit: trueclimateskeptics\n",
      "0 comments among all posts in subreddit: WorldClimate\n"
     ]
    }
   ],
   "source": [
    "for subreddit_tsv in glob.glob('praw_output/posts/*.tsv'):\n",
    "    if os.path.exists('praw_output/post_comments/{}_COMMENTS.tsv'.format(subreddit_tsv.split('/')[-1][:-4])):\n",
    "        print('Already got comments for subreddit {}'.format(subreddit_tsv))\n",
    "    else:\n",
    "        subreddit_posts = pd.read_csv(subreddit_tsv,sep='\\t',header=0)\n",
    "        if len(subreddit_posts) > 0:\n",
    "            subreddit = str(subreddit_posts.iloc[0]['subreddit'])\n",
    "            posts_with_comments = subreddit_posts.loc[subreddit_posts.num_comments > 0]\n",
    "            if len(posts_with_comments) > 0:\n",
    "                print('Getting comments from posts in subreddit: {}'.format(subreddit))\n",
    "                for ix,row in posts_with_comments.iterrows():\n",
    "                    get_submission_comments(reddit,subreddit,row['id'])\n",
    "            else:\n",
    "                print('0 comments among all posts in subreddit: {}'.format(subreddit))\n",
    "        else:\n",
    "            print('Subreddit {} has no posts'.format(subreddit_tsv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Pushshift API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pushshift API uses the requests library to make requests to 3 possible endpoints:\n",
    "    \n",
    "* /reddit/comment/search (corresponding to a comment)\n",
    "* /reddit/submission/search (corresponding to a post)\n",
    "* /reddit/subreddit/search (corresponding to a subreddit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script below submits a request for a given query (i.e. keyword or set of keywords contained), a before and after date, and a given datatype (one of the 3 endpoints). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "api = PushshiftAPI()\n",
    "\n",
    "def getPushshiftData(query, after_str, before_str, datatype):\n",
    "    before_date = datetime.datetime.strptime(before_str, \"%m-%d-%Y\")\n",
    "    after_date = datetime.datetime.strptime(after_str, \"%m-%d-%Y\")\n",
    "    before_timestamp = int(datetime.datetime.timestamp(before_date))\n",
    "    after_timestamp = int(datetime.datetime.timestamp(after_date))\n",
    "    \n",
    "    query_prefix = 'title' if datatype == 'submission' else 'q'\n",
    "    url = 'https://api.pushshift.io/reddit/search/'+datatype+'/?'+\\\n",
    "            query_prefix+'='+str(query)+'&size=1000&after='+str(after_date)+\\\n",
    "            '&before='+str(before_date)\n",
    "    #print(url)\n",
    "    r = requests.get(url)\n",
    "    data = json.loads(r.text)\n",
    "    \n",
    "    return data['data']\n",
    "\n",
    "def getPushshiftDataForSub(subreddit, query, y2, m2, d2, y1, m1, d1, datatype, limit=10000):\n",
    "    \n",
    "    before = int(dt.datetime(y1,m1,d1,0,0).timestamp())\n",
    "    after = int(dt.datetime(y2,m2,d2,0,0).timestamp())\n",
    "    \n",
    "    if datatype=='submissions':\n",
    "        out = api.search_submissions(subreddit=subreddit, q=query, limit=limit, \n",
    "                             before=before, after=after)\n",
    "    else:\n",
    "        out = api.search_comments(subreddit=subreddit, q=query, limit=limit, \n",
    "                             before=before, after=after)\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E.g., to get all posts containing 'climate change' between Jan. 1, 2020 and Feb. 1, 2020, we run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Not all PushShift shards are active. Query results may be incomplete.\n",
      "Not all PushShift shards are active. Query results may be incomplete.\n",
      "Not all PushShift shards are active. Query results may be incomplete.\n",
      "Not all PushShift shards are active. Query results may be incomplete.\n",
      "Not all PushShift shards are active. Query results may be incomplete.\n",
      "Not all PushShift shards are active. Query results may be incomplete.\n",
      "Not all PushShift shards are active. Query results may be incomplete.\n",
      "Not all PushShift shards are active. Query results may be incomplete.\n",
      "Not all PushShift shards are active. Query results may be incomplete.\n",
      "Not all PushShift shards are active. Query results may be incomplete.\n",
      "Not all PushShift shards are active. Query results may be incomplete.\n",
      "Not all PushShift shards are active. Query results may be incomplete.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total:: Success Rate: 100.00% - Requests: 101 - Batches: 11 - Items Remaining: 0\n"
     ]
    }
   ],
   "source": [
    "comments = getPushshiftDataForSub('changemyview',None,2014,1,1,2014,12,31,\n",
    "                                  'comments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>body</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>distinguished</th>\n",
       "      <th>gilded</th>\n",
       "      <th>id</th>\n",
       "      <th>link_id</th>\n",
       "      <th>...</th>\n",
       "      <th>reply_delay</th>\n",
       "      <th>retrieved_on</th>\n",
       "      <th>score</th>\n",
       "      <th>score_hidden</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>author_created_utc</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>user_removed</th>\n",
       "      <th>edited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[deleted]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Why are your stance that women can't enjoy dar...</td>\n",
       "      <td>0</td>\n",
       "      <td>1397998076</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>cgx96ag</td>\n",
       "      <td>t3_23erso</td>\n",
       "      <td>...</td>\n",
       "      <td>119858</td>\n",
       "      <td>1433438423</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>changemyview</td>\n",
       "      <td>t5_2w2s8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UncharminglyWitty</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>What about a kid walking home from school?</td>\n",
       "      <td>0</td>\n",
       "      <td>1397997927</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>cgx957p</td>\n",
       "      <td>t3_23hgnt</td>\n",
       "      <td>...</td>\n",
       "      <td>22288</td>\n",
       "      <td>1433438410</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>changemyview</td>\n",
       "      <td>t5_2w2s8</td>\n",
       "      <td>1.366138e+09</td>\n",
       "      <td>t2_bc9qn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>garnteller</td>\n",
       "      <td>None</td>\n",
       "      <td>108Δ</td>\n",
       "      <td>A few thoughts:\\n\\n1. **Ownership of a sub** F...</td>\n",
       "      <td>0</td>\n",
       "      <td>1397997921</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>cgx956g</td>\n",
       "      <td>t3_23i0xv</td>\n",
       "      <td>...</td>\n",
       "      <td>13103</td>\n",
       "      <td>1433438409</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>changemyview</td>\n",
       "      <td>t5_2w2s8</td>\n",
       "      <td>1.386191e+09</td>\n",
       "      <td>t2_e7e7z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>theivesinthenight</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes they do have to change their actions. You ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1397997882</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>cgx94vw</td>\n",
       "      <td>t3_23ev1v</td>\n",
       "      <td>...</td>\n",
       "      <td>919</td>\n",
       "      <td>1433438404</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>changemyview</td>\n",
       "      <td>t5_2w2s8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-moose-</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>http://www.reddit.com/r/moosearchive/comments/...</td>\n",
       "      <td>0</td>\n",
       "      <td>1397997836</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>cgx94jp</td>\n",
       "      <td>t3_23dc1g</td>\n",
       "      <td>...</td>\n",
       "      <td>132438</td>\n",
       "      <td>1433438401</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>changemyview</td>\n",
       "      <td>t5_2w2s8</td>\n",
       "      <td>1.369286e+09</td>\n",
       "      <td>t2_brzdj</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              author author_flair_css_class author_flair_text  \\\n",
       "0          [deleted]                   None              None   \n",
       "1  UncharminglyWitty                   None              None   \n",
       "2         garnteller                   None              108Δ   \n",
       "3  theivesinthenight                   None              None   \n",
       "4            -moose-                   None              None   \n",
       "\n",
       "                                                body  controversiality  \\\n",
       "0  Why are your stance that women can't enjoy dar...                 0   \n",
       "1         What about a kid walking home from school?                 0   \n",
       "2  A few thoughts:\\n\\n1. **Ownership of a sub** F...                 0   \n",
       "3  Yes they do have to change their actions. You ...                 0   \n",
       "4  http://www.reddit.com/r/moosearchive/comments/...                 0   \n",
       "\n",
       "   created_utc distinguished  gilded       id    link_id  ...  reply_delay  \\\n",
       "0   1397998076          None       0  cgx96ag  t3_23erso  ...       119858   \n",
       "1   1397997927          None       0  cgx957p  t3_23hgnt  ...        22288   \n",
       "2   1397997921          None       0  cgx956g  t3_23i0xv  ...        13103   \n",
       "3   1397997882          None       0  cgx94vw  t3_23ev1v  ...          919   \n",
       "4   1397997836          None       0  cgx94jp  t3_23dc1g  ...       132438   \n",
       "\n",
       "  retrieved_on  score  score_hidden     subreddit  subreddit_id  \\\n",
       "0   1433438423      0         False  changemyview      t5_2w2s8   \n",
       "1   1433438410      2         False  changemyview      t5_2w2s8   \n",
       "2   1433438409      2         False  changemyview      t5_2w2s8   \n",
       "3   1433438404      1         False  changemyview      t5_2w2s8   \n",
       "4   1433438401      1         False  changemyview      t5_2w2s8   \n",
       "\n",
       "  author_created_utc author_fullname  user_removed edited  \n",
       "0                NaN             NaN           NaN    NaN  \n",
       "1       1.366138e+09        t2_bc9qn           NaN    NaN  \n",
       "2       1.386191e+09        t2_e7e7z           NaN    NaN  \n",
       "3                NaN             NaN           NaN    NaN  \n",
       "4       1.369286e+09        t2_brzdj           NaN    NaN  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df = pd.DataFrame(comments)\n",
    "# preview the comments data\n",
    "comments_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#comments_df['selftext'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['global warming',\n",
       " 'climate change',\n",
       " 'carbon dioxide',\n",
       " 'co2',\n",
       " 'methane',\n",
       " 'fossil fuel',\n",
       " 'climate crisis',\n",
       " 'climate emergency',\n",
       " 'extreme weather',\n",
       " 'clean energy',\n",
       " 'renewable energy',\n",
       " 'cap and trade',\n",
       " 'sea level rise',\n",
       " 'IPCC',\n",
       " 'deforestation',\n",
       " 'permafrost',\n",
       " 'greenhouse gas',\n",
       " 'greenhouse effect',\n",
       " 'green new deal',\n",
       " 'environmentalism',\n",
       " 'EPA']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KEYWORDS_HI_PREC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     2
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Collect all posts w/ climate change keyword from CMV  \n",
    "\n",
    "# for start_year in range(2013,2022,1):\n",
    "#     for keyword in KEYWORDS_HI_PREC:\n",
    "#         save_dir = os.path.join('pmaw_output','submissions','changemyview',\n",
    "#                                 '1-1-{}_to_12-31-{}'.format(start_year,start_year))\n",
    "#         if not os.path.exists(save_dir):\n",
    "#             os.makedirs(save_dir)\n",
    "#         save_path = os.path.join(save_dir,'{}.csv'.format(keyword))\n",
    "#         if not os.path.exists(save_path):\n",
    "#             print(\"Missing {}, {}\".format(keyword,start_year))\n",
    "#             posts = getPushshiftDataForSub('changemyview',keyword,\n",
    "#                                            start_year,1,1,start_year,12,31,\n",
    "#                                            'submissions')\n",
    "#             posts_df = pd.DataFrame(posts)\n",
    "#             posts_df.to_csv(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all posts from CMV as background--comments seem incomplete\n",
    "\n",
    "for start_year in range(2013,2022,1):\n",
    "    #for keyword in KEYWORDS_HI_PREC:\n",
    "        #save_dir = os.path.join('pmaw_output','submissions','changemyview_background',\n",
    "        #                        '1-1-{}_to_12-31-{}'.format(start_year,start_year))\n",
    "        #if not os.path.exists(save_dir):\n",
    "        #    os.makedirs(save_dir)\n",
    "    save_path = os.path.join('pmaw_output','posts','changemyview_background',\n",
    "                                '1-1-{}_to_12-31-{}.csv'.format(start_year,start_year))\n",
    "    if not os.path.exists(save_path):\n",
    "        print(\"Missing background posts for {}\".format(start_year))\n",
    "        posts = getPushshiftDataForSub('changemyview',None,\n",
    "                                       start_year,1,1,start_year,12,31,\n",
    "                                       'ps')\n",
    "        posts_df = pd.DataFrame(posts)\n",
    "        posts_df.to_csv(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of df, pre-deduplication: 90016\n",
      "Size of df, post-deduplication: 90001\n",
      "False    52075\n",
      "True     37926\n",
      "Name: changed_view, dtype: int64\n",
      "\n",
      "Saving deduplicated df of posts to: pmaw_output/post_comments/changemyview_background/        1-1-2010_to_09-24-2021.csv\n"
     ]
    }
   ],
   "source": [
    "# Collect all comments from CMV as background\n",
    "\n",
    "for start_year in range(2013,2022,1):\n",
    "    #for keyword in KEYWORDS_HI_PREC:\n",
    "        #save_dir = os.path.join('pmaw_output','submissions','changemyview_background',\n",
    "        #                        '1-1-{}_to_12-31-{}'.format(start_year,start_year))\n",
    "        #if not os.path.exists(save_dir):\n",
    "        #    os.makedirs(save_dir)\n",
    "    save_path = os.path.join('pmaw_output','post_comments','changemyview_background',\n",
    "                                '1-1-{}_to_12-31-{}.csv'.format(start_year,start_year))\n",
    "    if not os.path.exists(save_path):\n",
    "        print(\"Missing background posts for {}\".format(start_year))\n",
    "        posts = getPushshiftDataForSub('changemyview',None,\n",
    "                                       start_year,1,1,start_year,12,31,\n",
    "                                       'comments')\n",
    "        posts_df = pd.DataFrame(posts)\n",
    "        posts_df.to_csv(save_path)\n",
    "        \n",
    "# Append individual dataframes into one large one to share\n",
    "\n",
    "df = pd.DataFrame(columns=list(COLUMNS)+['keyword'])\n",
    "\n",
    "for start_year in range(2013,2022,1):\n",
    "    save_path = os.path.join('pmaw_output','post_comments','changemyview_background',\n",
    "                                '1-1-{}_to_12-31-{}.csv'.format(start_year,start_year))\n",
    "    df_ = pd.read_csv(save_path,index_col=0)\n",
    "    if len(df_) > 0:\n",
    "        missing_cols = set(df.columns).difference(set(df_.columns))\n",
    "        for missing_col in missing_cols:\n",
    "            df_[missing_col] = [None]*len(df_)\n",
    "        df = pd.concat([df,df_],ignore_index=True,axis=0)\n",
    "        \n",
    "# Deduplicate by ID \n",
    "print('Size of df, pre-deduplication:',len(df))\n",
    "df.drop_duplicates(subset='id',inplace=True)\n",
    "print('Size of df, post-deduplication:',len(df))\n",
    "\n",
    "# Annotate with whether comment awarded delta or not (if ∆ is present in `author_flair_text`)\n",
    "df['changed_view'] = df['author_flair_text'].apply(\n",
    "                            lambda x: '∆' in x if type(x) == str else False\n",
    ")\n",
    "print(df['changed_view'].value_counts())\n",
    "\n",
    "# UPDATE TO CURRENT DATE\n",
    "from datetime import date\n",
    "today = date.today()\n",
    "str_today = today.strftime(\"%m-%d-%Y\")\n",
    "print('\\nSaving deduplicated df of posts to: pmaw_output/post_comments/changemyview_background/\\\n",
    "        1-1-2010_to_{}.csv'.format(str_today))\n",
    "\n",
    "df.to_csv('pmaw_output/post_comments/changemyview_background/1-1-2010_to_{}.csv'.format(str_today))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['author', 'author_created_utc', 'author_flair_css_class',\n",
       "       'author_flair_text', 'author_fullname', 'body', 'controversiality',\n",
       "       'created_utc', 'distinguished', 'gilded', 'id', 'link_id', 'nest_level',\n",
       "       'parent_id', 'reply_delay', 'retrieved_on', 'score', 'score_hidden',\n",
       "       'subreddit', 'subreddit_id', 'edited', 'user_removed', 'mod_removed',\n",
       "       'stickied'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    'pmaw_output/post_comments/changemyview_background/1-1-2015_to_12-31-2015.csv',\n",
    "index_col=0)\n",
    "COLUMNS = df.columns\n",
    "COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    2784\n",
      "True      392\n",
      "Name: delta_history, dtype: int64\n",
      "\n",
      "Saving deduplicated df of posts to: pmaw_output/submissions/changemyview/1-1-2010_to_09-22-2021.csv\n"
     ]
    }
   ],
   "source": [
    "# Append individual dataframes into one large one to share\n",
    "\n",
    "df = pd.DataFrame(columns=list(COLUMNS)+['keyword'])\n",
    "\n",
    "for start_year in range(2013,2022,1):\n",
    "    for keyword in KEYWORDS_HI_PREC:\n",
    "        save_dir = os.path.join('pmaw_output','submissions','changemyview',\n",
    "                                '1-1-{}_to_12-31-{}'.format(start_year,start_year))\n",
    "        save_path = os.path.join(save_dir,'{}.csv'.format(keyword))\n",
    "        df_ = pd.read_csv(save_path,index_col=0)\n",
    "        if len(df_) > 0:\n",
    "            df_['keyword'] = [keyword]*len(df_)\n",
    "            missing_cols = set(df.columns).difference(set(df_.columns))\n",
    "            for missing_col in missing_cols:\n",
    "                df_[missing_col] = [None]*len(df_)\n",
    "            df = pd.concat([df,df_],ignore_index=True,axis=0)\n",
    "        \n",
    "# Deduplicate by ID \n",
    "print('Size of df, pre-deduplication:',len(df))\n",
    "df.drop_duplicates(subset='id',inplace=True)\n",
    "print('Size of df, post-deduplication:',len(df))\n",
    "\n",
    "# Annotate with whether author awarded delta or not (if ∆ is present in `author_flair_text`)\n",
    "df['delta_history'] = df['author_flair_text'].apply(\n",
    "                            lambda x: '∆' in x if type(x) == str else False\n",
    ")\n",
    "print(df['delta_history'].value_counts())\n",
    "\n",
    "# UPDATE TO CURRENT DATE\n",
    "from datetime import date\n",
    "today = date.today()\n",
    "str_today = today.strftime(\"%m-%d-%Y\")\n",
    "print('\\nSaving deduplicated df of posts to: pmaw_output/submissions/changemyview/1-1-2010_to_{}.csv'.format(str_today))\n",
    "\n",
    "df.to_csv('pmaw_output/submissions/changemyview/1-1-2010_to_{}.csv'.format(str_today))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Inspect whether some keywords are low precision\n",
    "# for keyword in KEYWORDS_LONG:\n",
    "#     print(keyword)\n",
    "#     print(df.loc[df['keyword']==keyword]['url'].values[:10])\n",
    "#     print('=='*10+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    2784\n",
      "True      392\n",
      "Name: delta_history, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['delta_history'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>author_created_utc</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>domain</th>\n",
       "      <th>edited</th>\n",
       "      <th>full_link</th>\n",
       "      <th>gilded</th>\n",
       "      <th>...</th>\n",
       "      <th>steward_reports</th>\n",
       "      <th>og_description</th>\n",
       "      <th>og_title</th>\n",
       "      <th>removed_by_category</th>\n",
       "      <th>removed_by</th>\n",
       "      <th>media_metadata</th>\n",
       "      <th>is_created_from_ads_ui</th>\n",
       "      <th>author_is_blocked</th>\n",
       "      <th>awarded_delta</th>\n",
       "      <th>delta_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>patval</td>\n",
       "      <td>1.30124e+09</td>\n",
       "      <td>points</td>\n",
       "      <td>6∆</td>\n",
       "      <td>t2_50pzq</td>\n",
       "      <td>1404878570</td>\n",
       "      <td>self.changemyview</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/changemyview/comments...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ianw19</td>\n",
       "      <td>1.36656e+09</td>\n",
       "      <td>points</td>\n",
       "      <td>1∆</td>\n",
       "      <td>t2_bei5p</td>\n",
       "      <td>1404765167</td>\n",
       "      <td>self.changemyview</td>\n",
       "      <td>1.40656e+09</td>\n",
       "      <td>https://www.reddit.com/r/changemyview/comments...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>TEmpTom</td>\n",
       "      <td>1.32434e+09</td>\n",
       "      <td>points</td>\n",
       "      <td>3∆</td>\n",
       "      <td>t2_6h1tr</td>\n",
       "      <td>1404185778</td>\n",
       "      <td>self.changemyview</td>\n",
       "      <td>1.40419e+09</td>\n",
       "      <td>https://www.reddit.com/r/changemyview/comments...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Abstract_Atheist</td>\n",
       "      <td>1.3975e+09</td>\n",
       "      <td>points</td>\n",
       "      <td>1∆</td>\n",
       "      <td>t2_g4ixf</td>\n",
       "      <td>1403979277</td>\n",
       "      <td>self.changemyview</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/changemyview/comments...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>durutticolumn</td>\n",
       "      <td>1.39077e+09</td>\n",
       "      <td>points</td>\n",
       "      <td>7∆</td>\n",
       "      <td>t2_ezn09</td>\n",
       "      <td>1403215525</td>\n",
       "      <td>self.changemyview</td>\n",
       "      <td>1.40322e+09</td>\n",
       "      <td>https://www.reddit.com/r/changemyview/comments...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4429</th>\n",
       "      <td>-SeeMeNoMore-</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3∆</td>\n",
       "      <td>t2_5oiov2cv</td>\n",
       "      <td>1621084882</td>\n",
       "      <td>self.changemyview</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/changemyview/comments...</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4457</th>\n",
       "      <td>Recognizant</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11∆</td>\n",
       "      <td>t2_cyo9v</td>\n",
       "      <td>1631375392</td>\n",
       "      <td>self.changemyview</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/changemyview/comments...</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4464</th>\n",
       "      <td>TheFakeChiefKeef</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67∆</td>\n",
       "      <td>t2_3zbj5lrr</td>\n",
       "      <td>1612146828</td>\n",
       "      <td>self.changemyview</td>\n",
       "      <td>1.61215e+09</td>\n",
       "      <td>https://www.reddit.com/r/changemyview/comments...</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4509</th>\n",
       "      <td>Polar_Roid</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5∆</td>\n",
       "      <td>t2_6nje1aoq</td>\n",
       "      <td>1620689019</td>\n",
       "      <td>self.changemyview</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.reddit.com/r/changemyview/comments...</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4512</th>\n",
       "      <td>Zelentor</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1∆</td>\n",
       "      <td>t2_9jfeu518</td>\n",
       "      <td>1617643717</td>\n",
       "      <td>self.changemyview</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.reddit.com/r/changemyview/comments...</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>moderator</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392 rows × 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                author author_created_utc author_flair_css_class  \\\n",
       "22              patval        1.30124e+09                 points   \n",
       "24              ianw19        1.36656e+09                 points   \n",
       "25             TEmpTom        1.32434e+09                 points   \n",
       "27    Abstract_Atheist         1.3975e+09                 points   \n",
       "28       durutticolumn        1.39077e+09                 points   \n",
       "...                ...                ...                    ...   \n",
       "4429     -SeeMeNoMore-               None                    NaN   \n",
       "4457       Recognizant               None                    NaN   \n",
       "4464  TheFakeChiefKeef               None                    NaN   \n",
       "4509        Polar_Roid               None                    NaN   \n",
       "4512          Zelentor               None                    NaN   \n",
       "\n",
       "     author_flair_text author_fullname created_utc             domain  \\\n",
       "22                  6∆        t2_50pzq  1404878570  self.changemyview   \n",
       "24                  1∆        t2_bei5p  1404765167  self.changemyview   \n",
       "25                  3∆        t2_6h1tr  1404185778  self.changemyview   \n",
       "27                  1∆        t2_g4ixf  1403979277  self.changemyview   \n",
       "28                  7∆        t2_ezn09  1403215525  self.changemyview   \n",
       "...                ...             ...         ...                ...   \n",
       "4429                3∆     t2_5oiov2cv  1621084882  self.changemyview   \n",
       "4457               11∆        t2_cyo9v  1631375392  self.changemyview   \n",
       "4464               67∆     t2_3zbj5lrr  1612146828  self.changemyview   \n",
       "4509                5∆     t2_6nje1aoq  1620689019  self.changemyview   \n",
       "4512                1∆     t2_9jfeu518  1617643717  self.changemyview   \n",
       "\n",
       "           edited                                          full_link gilded  \\\n",
       "22            NaN  https://www.reddit.com/r/changemyview/comments...      0   \n",
       "24    1.40656e+09  https://www.reddit.com/r/changemyview/comments...      0   \n",
       "25    1.40419e+09  https://www.reddit.com/r/changemyview/comments...      0   \n",
       "27            NaN  https://www.reddit.com/r/changemyview/comments...      0   \n",
       "28    1.40322e+09  https://www.reddit.com/r/changemyview/comments...      0   \n",
       "...           ...                                                ...    ...   \n",
       "4429          NaN  https://www.reddit.com/r/changemyview/comments...   None   \n",
       "4457          NaN  https://www.reddit.com/r/changemyview/comments...   None   \n",
       "4464  1.61215e+09  https://www.reddit.com/r/changemyview/comments...   None   \n",
       "4509         None  https://www.reddit.com/r/changemyview/comments...   None   \n",
       "4512         None  https://www.reddit.com/r/changemyview/comments...   None   \n",
       "\n",
       "      ... steward_reports og_description og_title removed_by_category  \\\n",
       "22    ...             NaN            NaN      NaN                 NaN   \n",
       "24    ...             NaN            NaN      NaN                 NaN   \n",
       "25    ...             NaN            NaN      NaN                 NaN   \n",
       "27    ...             NaN            NaN      NaN                 NaN   \n",
       "28    ...             NaN            NaN      NaN                 NaN   \n",
       "...   ...             ...            ...      ...                 ...   \n",
       "4429  ...            None           None     None                None   \n",
       "4457  ...            None           None     None                None   \n",
       "4464  ...            None           None     None                None   \n",
       "4509  ...            None           None     None                 NaN   \n",
       "4512  ...            None           None     None           moderator   \n",
       "\n",
       "     removed_by media_metadata is_created_from_ads_ui author_is_blocked  \\\n",
       "22          NaN            NaN                    NaN               NaN   \n",
       "24          NaN            NaN                    NaN               NaN   \n",
       "25          NaN            NaN                    NaN               NaN   \n",
       "27          NaN            NaN                    NaN               NaN   \n",
       "28          NaN            NaN                    NaN               NaN   \n",
       "...         ...            ...                    ...               ...   \n",
       "4429       None           None                    NaN               NaN   \n",
       "4457       None           None                  False             False   \n",
       "4464       None           None                   None              None   \n",
       "4509       None           None                    NaN               NaN   \n",
       "4512       None           None                    NaN              None   \n",
       "\n",
       "     awarded_delta delta_history  \n",
       "22            True          True  \n",
       "24            True          True  \n",
       "25            True          True  \n",
       "27            True          True  \n",
       "28            True          True  \n",
       "...            ...           ...  \n",
       "4429          True          True  \n",
       "4457          True          True  \n",
       "4464          True          True  \n",
       "4509          True          True  \n",
       "4512          True          True  \n",
       "\n",
       "[392 rows x 92 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['delta_history']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Check API rate limiting\n",
    "# import datetime\n",
    "# start = datetime.datetime.now()\n",
    "# for req_no in range(0,400):\n",
    "#     post = reddit.submission(id=df['id'].values[req_no])\n",
    "#     c_ids = [c for c in post.comments]\n",
    "#     print('Post comments:',c_ids)\n",
    "#     elapsed = (datetime.datetime.now()-start).total_seconds() / 60\n",
    "#     print('Elapsed minutes:', elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "code_folding": [
     3,
     67
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get all comments on posts within big posts df\n",
    "\n",
    "# define FIELDS; initialize comments dataframe\n",
    "# FIELDS = set(['author_flair_text',\n",
    "#               'treatment_tags',\n",
    "#               'collapsed',\n",
    "#               'subreddit_name_prefixed',\n",
    "#               'controversiality',\n",
    "#               'collapsed_because_crowd_control',\n",
    "#               'mod_reports',\n",
    "#               'subreddit_type',\n",
    "#               'ups',\n",
    "#              '_replies',\n",
    "#              'id',\n",
    "#              'total_awards_received',\n",
    "#              'approved_at_utc',\n",
    "#              'author_is_blocked',\n",
    "#              'comment_type',\n",
    "#              'edited',\n",
    "#              'mod_reason_by',\n",
    "#              'banned_by',\n",
    "#              'author_flair_type',\n",
    "#              'removal_reason',\n",
    "#              'link_id',\n",
    "#              'likes',\n",
    "#              'author_fullname',\n",
    "#              'banned_at_utc',\n",
    "#              'mod_reason_title',\n",
    "#              'gilded',\n",
    "#              'archived',\n",
    "#              'collapsed_reason_code',\n",
    "#              'no_follow',\n",
    "#              'can_mod_post',\n",
    "#              'created_utc',\n",
    "#              'send_replies',\n",
    "#              'parent_id',\n",
    "#              'score',\n",
    "#              'approved_by',\n",
    "#              'author_premium',\n",
    "#              'mod_note',\n",
    "#              'all_awardings',\n",
    "#              'subreddit_id',\n",
    "#              'body',\n",
    "#              'awarders',\n",
    "#               'user_reports',\n",
    "#               'name',\n",
    "#               'downs',\n",
    "#               'author_flair_richtext',\n",
    "#               'is_submitter',\n",
    "#               'collapsed_reason',\n",
    "#               'distinguished',\n",
    "#               'associated_award',\n",
    "#               'stickied',\n",
    "#               'can_gild',\n",
    "#               'top_awarded_type',\n",
    "#               'score_hidden',\n",
    "#               'permalink',\n",
    "#               'num_reports',\n",
    "#               'locked',\n",
    "#               'report_reasons',\n",
    "#               'created'\n",
    "#              ])\n",
    "# with open('reddit_comment_fields.txt','w') as f:\n",
    "#     for field in FIELDS:\n",
    "#         f.write(field+'\\n')\n",
    "# comments_dict = defaultdict(list)\n",
    "\n",
    "# for n,p_id in enumerate(df['id'].values[2476:]):\n",
    "#     #print(p_id)\n",
    "#     post = reddit.submission(id=p_id)\n",
    "#     c_ids = [c.id for c in post.comments]\n",
    "#     #print('Post comments:',c_ids)\n",
    "#     for c_id in c_ids:\n",
    "#         comment = reddit.comment(c_id)\n",
    "#         try:\n",
    "#             comments_dict['author_flair_text'].append(comment.author_flair_text)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['author_flair_text'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['treatment_tags'].append(comment.treatment_tags)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['treatment_tags'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['collapsed'].append(comment.collapsed)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['collapsed'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['subreddit_name_prefixed'].append(comment.subreddit_name_prefixed)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['subreddit_name_prefixed'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['controversiality'].append(comment.controversiality)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['controversiality'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['collapsed_because_crowd_control'].append(comment.collapsed_because_crowd_control)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['collapsed_because_crowd_control'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['mod_reports'].append(comment.mod_reports)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['mod_reports'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['subreddit_type'].append(comment.subreddit_type)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['subreddit_type'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['ups'].append(comment.ups)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['ups'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['_replies'].append(comment._replies)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['_replies'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['id'].append(comment.id)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['id'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['total_awards_received'].append(comment.total_awards_received)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['total_awards_received'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['approved_at_utc'].append(comment.approved_at_utc)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['approved_at_utc'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['author_is_blocked'].append(comment.author_is_blocked)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['author_is_blocked'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['comment_type'].append(comment.comment_type)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['comment_type'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['edited'].append(comment.edited)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['edited'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['mod_reason_by'].append(comment.mod_reason_by)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['mod_reason_by'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['banned_by'].append(comment.banned_by)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['banned_by'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['author_flair_type'].append(comment.author_flair_type)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['author_flair_type'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['removal_reason'].append(comment.removal_reason)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['removal_reason'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['link_id'].append(comment.link_id)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['link_id'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['likes'].append(comment.likes)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['likes'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['author_fullname'].append(comment.author_fullname)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['author_fullname'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['banned_at_utc'].append(comment.banned_at_utc)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['banned_at_utc'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['mod_reason_title'].append(comment.mod_reason_title)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['mod_reason_title'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['gilded'].append(comment.gilded)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['gilded'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['archived'].append(comment.archived)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['archived'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['collapsed_reason_code'].append(comment.collapsed_reason_code)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['collapsed_reason_code'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['no_follow'].append(comment.no_follow)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['no_follow'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['can_mod_post'].append(comment.can_mod_post)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['can_mod_post'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['created_utc'].append(comment.created_utc)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['created_utc'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['send_replies'].append(comment.send_replies)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['send_replies'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['parent_id'].append(comment.parent_id)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['parent_id'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['score'].append(comment.score)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['score'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['approved_by'].append(comment.approved_by)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['approved_by'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['author_premium'].append(comment.author_premium)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['author_premium'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['mod_note'].append(comment.mod_note)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['mod_note'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['all_awardings'].append(comment.all_awardings)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['all_awardings'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['subreddit_id'].append(comment.subreddit_id)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['subreddit_id'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['body'].append(comment.body)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['body'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['awarders'].append(comment.awarders)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['awarders'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['user_reports'].append(comment.user_reports)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['user_reports'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['name'].append(comment.name)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['name'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['downs'].append(comment.downs)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['downs'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['author_flair_richtext'].append(comment.author_flair_richtext)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['author_flair_richtext'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['is_submitter'].append(comment.is_submitter)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['is_submitter'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['collapsed_reason'].append(comment.collapsed_reason)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['collapsed_reason'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['distinguished'].append(comment.distinguished)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['distinguished'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['associated_award'].append(comment.associated_award)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['associated_award'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['stickied'].append(comment.stickied)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['stickied'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['can_gild'].append(comment.can_gild)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['can_gild'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['top_awarded_type'].append(comment.top_awarded_type)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['top_awarded_type'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['score_hidden'].append(comment.score_hidden)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['score_hidden'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['permalink'].append(comment.permalink)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['permalink'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['num_reports'].append(comment.num_reports)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['num_reports'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['locked'].append(comment.locked)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['locked'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['report_reasons'].append(comment.report_reasons)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['report_reasons'].append(None)\n",
    "#         try:\n",
    "#             comments_dict['created'].append(comment.created)\n",
    "#         except AttributeError:\n",
    "#             comments_dict['created'].append(None)\n",
    "\n",
    "#     if n % 10 == 0:\n",
    "#         print(n)\n",
    "\n",
    "# comments_df = pd.DataFrame(comments_dict)\n",
    "# print(comments_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    21604\n",
       "True     15630\n",
       "Name: changed_view, dtype: int64"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And annotate with whether comment received delta or not\n",
    "# (look at `author_flair_text`)\n",
    "comments_df['changed_view'] = comments_df['author_flair_text'].apply(\n",
    "    lambda x: '∆' in x if type(x) == str else False\n",
    ")\n",
    "comments_df['changed_view'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37234, 59)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>treatment_tags</th>\n",
       "      <th>collapsed</th>\n",
       "      <th>subreddit_name_prefixed</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>collapsed_because_crowd_control</th>\n",
       "      <th>mod_reports</th>\n",
       "      <th>subreddit_type</th>\n",
       "      <th>ups</th>\n",
       "      <th>_replies</th>\n",
       "      <th>...</th>\n",
       "      <th>stickied</th>\n",
       "      <th>can_gild</th>\n",
       "      <th>top_awarded_type</th>\n",
       "      <th>score_hidden</th>\n",
       "      <th>permalink</th>\n",
       "      <th>num_reports</th>\n",
       "      <th>locked</th>\n",
       "      <th>report_reasons</th>\n",
       "      <th>created</th>\n",
       "      <th>changed_view</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>r/changemyview</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>public</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/changemyview/comments/1vxyf3/i_believe_that...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1.390489e+09</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>r/changemyview</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>public</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/changemyview/comments/1vxyf3/i_believe_that...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1.390493e+09</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>r/changemyview</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>public</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/changemyview/comments/1vxyf3/i_believe_that...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1.390494e+09</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20∆</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>r/changemyview</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>public</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/changemyview/comments/1vxyf3/i_believe_that...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1.390499e+09</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>r/changemyview</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>public</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/changemyview/comments/1vps5i/i_am_an_18_yea...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1.390268e+09</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  author_flair_text treatment_tags  collapsed subreddit_name_prefixed  \\\n",
       "0                               []      False          r/changemyview   \n",
       "1              None             []      False          r/changemyview   \n",
       "2              None             []      False          r/changemyview   \n",
       "3               20∆             []      False          r/changemyview   \n",
       "4              None             []      False          r/changemyview   \n",
       "\n",
       "   controversiality collapsed_because_crowd_control mod_reports  \\\n",
       "0                 0                            None          []   \n",
       "1                 0                            None          []   \n",
       "2                 0                            None          []   \n",
       "3                 0                            None          []   \n",
       "4                 0                            None          []   \n",
       "\n",
       "  subreddit_type  ups _replies  ... stickied  can_gild top_awarded_type  \\\n",
       "0         public    3       []  ...    False      True             None   \n",
       "1         public    3       []  ...    False      True             None   \n",
       "2         public    2       []  ...    False      True             None   \n",
       "3         public    2       []  ...    False      True             None   \n",
       "4         public    4       []  ...    False      True             None   \n",
       "\n",
       "   score_hidden                                          permalink  \\\n",
       "0         False  /r/changemyview/comments/1vxyf3/i_believe_that...   \n",
       "1         False  /r/changemyview/comments/1vxyf3/i_believe_that...   \n",
       "2         False  /r/changemyview/comments/1vxyf3/i_believe_that...   \n",
       "3         False  /r/changemyview/comments/1vxyf3/i_believe_that...   \n",
       "4         False  /r/changemyview/comments/1vps5i/i_am_an_18_yea...   \n",
       "\n",
       "  num_reports locked report_reasons       created changed_view  \n",
       "0        None  False           None  1.390489e+09        False  \n",
       "1        None  False           None  1.390493e+09        False  \n",
       "2        None  False           None  1.390494e+09        False  \n",
       "3        None  False           None  1.390499e+09         True  \n",
       "4        None  False           None  1.390268e+09        False  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.makedirs('comments_output/changemyview')\n",
    "comments_df.to_csv('comments_output/changemyview/from_posts_1-1-2010_to_9-22-2021.csv',\n",
    "                  index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# OLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "However, the API only returns 100 results at a time, so we need some additional wrapper scripts to iteratively retrieve all results. \n",
    "\n",
    "`collectSubData` gets specific fields we want from a post and `collectCommData` does the same but for a comment. Check out [this doc page](#https://pushshift.io/api-parameters/) for details on how you can modify these 2 scripts to change the fields you might be interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "code_folding": [
     0,
     55,
     56
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def collectSubData(subm,subs_dict):\n",
    "    try:\n",
    "        title = subm['title']\n",
    "    except KeyError:\n",
    "        title = None\n",
    "    try:\n",
    "        url = subm['url']\n",
    "    except KeyError:\n",
    "        url = None\n",
    "    try:\n",
    "        flair = subm['link_flair_text']\n",
    "    except KeyError:\n",
    "        flair = \"NaN\"   \n",
    "    try:\n",
    "        author = subm['author']\n",
    "    except KeyError:\n",
    "        author = None\n",
    "    sub_id = subm['id']\n",
    "    try:\n",
    "        score = subm['score']\n",
    "    except KeyError:\n",
    "        score = None\n",
    "    try:\n",
    "        created = datetime.datetime.fromtimestamp(subm['created_utc']) #1520561700.0\n",
    "    except KeyError:\n",
    "        created = None\n",
    "    try:\n",
    "        numComms = subm['num_comments']\n",
    "    except KeyError:\n",
    "        numComms = None\n",
    "    try:\n",
    "        permalink = subm['permalink']\n",
    "    except KeyError:\n",
    "        permalink = None\n",
    "    try:\n",
    "        is_vid = subm['is_video']\n",
    "    except KeyError:\n",
    "        is_vid = None\n",
    "    try:\n",
    "        upvote_ratio = subm['upvote_ratio']\n",
    "    except KeyError:\n",
    "        upvote_ratio = None\n",
    "    try:\n",
    "        text = subm['selftext'].strip().replace('\\t','').replace('\\n','')\n",
    "    except KeyError:\n",
    "        text = \"\"\n",
    "    try:\n",
    "        subreddit = subm['subreddit']\n",
    "    except KeyError:\n",
    "        subreddit = None\n",
    "    subData = {'id':sub_id,'title':title,'url':url,'author':author,'score':score,'date':created,\n",
    "                    'num_comments':numComms,'permalink':permalink,'flair':flair,'is_video':is_vid,\n",
    "                    'upvote_ratio':upvote_ratio,'text':text,'subreddit':subreddit}\n",
    "    subs_dict[sub_id] = subData\n",
    "    \n",
    "def collectCommData(subm,subs_dict): \n",
    "    try:\n",
    "        author = subm['author']\n",
    "    except KeyError:\n",
    "        author = None\n",
    "    sub_id = subm['id']\n",
    "    try:\n",
    "        link_id = subm['link_id']\n",
    "    except KeyError:\n",
    "        link_id = None\n",
    "    try:\n",
    "        score = subm['score']\n",
    "    except KeyError:\n",
    "        score = None\n",
    "    try:\n",
    "        created = datetime.datetime.fromtimestamp(subm['created_utc']) #1520561700.0\n",
    "    except KeyError:\n",
    "        created = None\n",
    "    try:\n",
    "        permalink = subm['permalink']\n",
    "    except KeyError:\n",
    "        permalink = None\n",
    "    try:\n",
    "        text = subm['body'].strip().replace('\\t','').replace('\\n','')\n",
    "    except KeyError:\n",
    "        text = \"\"\n",
    "    try:\n",
    "        subreddit = subm['subreddit']\n",
    "    except KeyError:\n",
    "        subreddit = None\n",
    "    subData = {'id':sub_id,'link_id':link_id,'author':author,'score':score,'date':created,\n",
    "                    'permalink':permalink,'text':text,'subreddit':subreddit}\n",
    "    subs_dict[sub_id] = subData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Then, we can call `pushshift_wrapper` to run until all data has been gathered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def pushshift_wrapper(after_str, before_str, datatype, \n",
    "                      subreddit=None, query=None, keywords=None):\n",
    "    failed_requests = []\n",
    "    \n",
    "    if query is None:\n",
    "        query = '|'.join(keywords)\n",
    "    \n",
    "    subCount = 0\n",
    "    subStats = {}\n",
    "    print(\"Getting all submissions with query '{}' within subreddit {} from {} to {}\".format(\n",
    "        query,subreddit,after_str,before_str))\n",
    "    try:\n",
    "        data = getPushshiftDataForSub(subreddit, query, after_str, before_str, datatype)\n",
    "        # Will run until all posts have been gathered \n",
    "        # from the 'after' date up until before date\n",
    "        while len(data) > 0:\n",
    "            for submission in data:\n",
    "                if datatype == \"submission\":\n",
    "                    collectSubData(submission,subStats)\n",
    "                else:\n",
    "                    collectCommData(submission,subStats)\n",
    "                subCount+=1\n",
    "            # Calls getPushshiftData() with the created date of the last submission\n",
    "            #print(len(data))\n",
    "#             print(str(datetime.datetime.fromtimestamp(data[-1]['created_utc'])))\n",
    "#             after_timestamp = data[-1]['created_utc']\n",
    "            \n",
    "            new_after_str = str(datetime.datetime.fromtimestamp(data[-1]['created_utc'])).\\\n",
    "                            split()[0]\n",
    "            split_after_str = new_after_str.split('-')\n",
    "            new_after_str = '{}-{}-{}'.format(split_after_str[1],split_after_str[2],\n",
    "                                             split_after_str[0])\n",
    "            print(new_after_str)\n",
    "            try:\n",
    "                data = getPushshiftDataForSub(subreddit, query, \n",
    "                                              new_after_str, before_str, datatype)\n",
    "            except JSONDecodeError:\n",
    "                failed_requests.append((subreddit,query,after_str,before_str,datatype))\n",
    "\n",
    "        print('Num submissions:',subCount,len(subStats))\n",
    "\n",
    "        interim_df = pd.DataFrame(list(subStats.values()))\n",
    "        #print(interim_df)\n",
    "\n",
    "        datatype_prefix = 'posts' if datatype == 'submission' else 'post_comments'\n",
    "        out_dir = os.path.join('pushshift_output',datatype_prefix,subreddit,'{}_to_{}'.format(after_str,before_str))\n",
    "        failed_reqs_out_dir = os.path.join('pushshift_output','failed_requests',subreddit,\n",
    "                                                      '{}_{}'.format(after_str,before_str))\n",
    "        if not os.path.exists(out_dir):\n",
    "            os.makedirs(out_dir)\n",
    "        if not os.path.exists(failed_reqs_out_dir):\n",
    "            os.makedirs(failed_reqs_out_dir)\n",
    "            \n",
    "        if keywords is None:\n",
    "            interim_df.to_pickle(os.path.join(out_dir,'{}.pkl'.format(query)))\n",
    "            print('Saved query submissions to {}!'.format(os.path.join(out_dir,'{}.pkl'.format(query))))\n",
    "            pickle.dump(failed_requests,open(os.path.join(failed_reqs_out_dir,'{}.pkl'.format(query)),'wb'))\n",
    "        else:\n",
    "            interim_df.to_pickle(os.path.join(out_dir,'{}.pkl'.format('keywords_long')))\n",
    "            print('Saved query submissions to {}!'.format(os.path.join(out_dir,'{}.pkl'.format('keywords_long'))))\n",
    "            pickle.dump(failed_requests,open(os.path.join(failed_reqs_out_dir,'{}.pkl'.format('keywords_long')),'wb'))\n",
    "            \n",
    "    except JSONDecodeError:\n",
    "        failed_requests.append((query,after_str,before_str,datatype))\n",
    "        print(\"First request failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting all submissions with query 'climate change' within subreddit changemyview from 01-01-2014 to 1-5-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n",
      "01-03-2014\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-1400cfbe7f1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m pushshift_wrapper('01-01-2014','1-5-2014','submission',subreddit='changemyview',\n\u001b[0;32m----> 2\u001b[0;31m                  query='climate change')\n\u001b[0m",
      "\u001b[0;32m<ipython-input-70-9c0fe95f5103>\u001b[0m in \u001b[0;36mpushshift_wrapper\u001b[0;34m(after_str, before_str, datatype, subreddit, query, keywords)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 data = getPushshiftDataForSub(subreddit, query, \n\u001b[0;32m---> 36\u001b[0;31m                                               new_after_str, before_str, datatype)\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0mfailed_requests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubreddit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mafter_str\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbefore_str\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-64aed0d93794>\u001b[0m in \u001b[0;36mgetPushshiftDataForSub\u001b[0;34m(subreddit, query, after_str, before_str, datatype)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;34m'&before='\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbefore_date\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m#print(url)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/nlp/anaconda/main/anaconda3/envs/yiwei-climate/lib/python3.6/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/nlp/anaconda/main/anaconda3/envs/yiwei-climate/lib/python3.6/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/nlp/anaconda/main/anaconda3/envs/yiwei-climate/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    531\u001b[0m         }\n\u001b[1;32m    532\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/nlp/anaconda/main/anaconda3/envs/yiwei-climate/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/nlp/anaconda/main/anaconda3/envs/yiwei-climate/lib/python3.6/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/nlp/anaconda/main/anaconda3/envs/yiwei-climate/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    675\u001b[0m                 \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m             )\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/nlp/anaconda/main/anaconda3/envs/yiwei-climate/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;31m# Trigger any extra validation we need to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;31m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/nlp/anaconda/main/anaconda3/envs/yiwei-climate/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    976\u001b[0m         \u001b[0;31m# Force connect early to allow us to validate the connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sock\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_verified\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/nlp/anaconda/main/anaconda3/envs/yiwei-climate/lib/python3.6/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    369\u001b[0m             \u001b[0mca_cert_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mca_cert_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m             \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m             \u001b[0mssl_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m         )\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/nlp/anaconda/main/anaconda3/envs/yiwei-climate/lib/python3.6/site-packages/urllib3/util/ssl_.py\u001b[0m in \u001b[0;36mssl_wrap_socket\u001b[0;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data)\u001b[0m\n\u001b[1;32m    350\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mca_certs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mca_cert_dir\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mca_cert_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_verify_locations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mca_certs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mca_cert_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mca_cert_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Platform-specific: Python 2.7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pushshift_wrapper('01-01-2014','1-5-2014','submission',subreddit='changemyview',\n",
    "                 query='climate change')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing global warming, 2010\n",
      "Getting all submissions with query 'global warming' within subreddit changemyview from 1-1-2010 to 12-31-2010\n",
      "Num submissions: 0 0\n",
      "Saved query submissions to pushshift_output/posts/changemyview/1-1-2010_to_12-31-2010/global warming.pkl!\n",
      "Missing climate change, 2010\n",
      "Getting all submissions with query 'climate change' within subreddit changemyview from 1-1-2010 to 12-31-2010\n",
      "Num submissions: 0 0\n",
      "Saved query submissions to pushshift_output/posts/changemyview/1-1-2010_to_12-31-2010/climate change.pkl!\n",
      "Missing carbon, 2010\n",
      "Getting all submissions with query 'carbon' within subreddit changemyview from 1-1-2010 to 12-31-2010\n",
      "Num submissions: 0 0\n",
      "Saved query submissions to pushshift_output/posts/changemyview/1-1-2010_to_12-31-2010/carbon.pkl!\n",
      "Missing fossil fuel, 2010\n",
      "Getting all submissions with query 'fossil fuel' within subreddit changemyview from 1-1-2010 to 12-31-2010\n",
      "Num submissions: 0 0\n",
      "Saved query submissions to pushshift_output/posts/changemyview/1-1-2010_to_12-31-2010/fossil fuel.pkl!\n",
      "Missing methane, 2010\n",
      "Getting all submissions with query 'methane' within subreddit changemyview from 1-1-2010 to 12-31-2010\n",
      "Num submissions: 0 0\n",
      "Saved query submissions to pushshift_output/posts/changemyview/1-1-2010_to_12-31-2010/methane.pkl!\n",
      "Missing environment, 2010\n",
      "Getting all submissions with query 'environment' within subreddit changemyview from 1-1-2010 to 12-31-2010\n",
      "Num submissions: 0 0\n",
      "Saved query submissions to pushshift_output/posts/changemyview/1-1-2010_to_12-31-2010/environment.pkl!\n",
      "Missing co2, 2010\n",
      "Getting all submissions with query 'co2' within subreddit changemyview from 1-1-2010 to 12-31-2010\n",
      "Num submissions: 0 0\n",
      "Saved query submissions to pushshift_output/posts/changemyview/1-1-2010_to_12-31-2010/co2.pkl!\n",
      "Missing climate crisis, 2010\n",
      "Getting all submissions with query 'climate crisis' within subreddit changemyview from 1-1-2010 to 12-31-2010\n",
      "Num submissions: 0 0\n",
      "Saved query submissions to pushshift_output/posts/changemyview/1-1-2010_to_12-31-2010/climate crisis.pkl!\n",
      "Missing climate emergency, 2010\n",
      "Getting all submissions with query 'climate emergency' within subreddit changemyview from 1-1-2010 to 12-31-2010\n",
      "Num submissions: 0 0\n",
      "Saved query submissions to pushshift_output/posts/changemyview/1-1-2010_to_12-31-2010/climate emergency.pkl!\n",
      "Missing extreme weather, 2010\n",
      "Getting all submissions with query 'extreme weather' within subreddit changemyview from 1-1-2010 to 12-31-2010\n",
      "First request failed\n",
      "Missing 2 degree, 2010\n",
      "Getting all submissions with query '2 degree' within subreddit changemyview from 1-1-2010 to 12-31-2010\n",
      "First request failed\n",
      "Missing sustainable, 2010\n",
      "Getting all submissions with query 'sustainable' within subreddit changemyview from 1-1-2010 to 12-31-2010\n",
      "First request failed\n",
      "Missing clean energy, 2010\n",
      "Getting all submissions with query 'clean energy' within subreddit changemyview from 1-1-2010 to 12-31-2010\n",
      "First request failed\n",
      "Missing renewable, 2010\n",
      "Getting all submissions with query 'renewable' within subreddit changemyview from 1-1-2010 to 12-31-2010\n",
      "Num submissions: 0 0\n",
      "Saved query submissions to pushshift_output/posts/changemyview/1-1-2010_to_12-31-2010/renewable.pkl!\n",
      "Missing cap and trade, 2010\n",
      "Getting all submissions with query 'cap and trade' within subreddit changemyview from 1-1-2010 to 12-31-2010\n",
      "Num submissions: 0 0\n",
      "Saved query submissions to pushshift_output/posts/changemyview/1-1-2010_to_12-31-2010/cap and trade.pkl!\n",
      "Missing sea level rise, 2010\n",
      "Getting all submissions with query 'sea level rise' within subreddit changemyview from 1-1-2010 to 12-31-2010\n",
      "Num submissions: 0 0\n",
      "Saved query submissions to pushshift_output/posts/changemyview/1-1-2010_to_12-31-2010/sea level rise.pkl!\n",
      "Missing environmental justice, 2010\n",
      "Getting all submissions with query 'environmental justice' within subreddit changemyview from 1-1-2010 to 12-31-2010\n",
      "Num submissions: 0 0\n",
      "Saved query submissions to pushshift_output/posts/changemyview/1-1-2010_to_12-31-2010/environmental justice.pkl!\n",
      "Missing climate justice, 2010\n",
      "Getting all submissions with query 'climate justice' within subreddit changemyview from 1-1-2010 to 12-31-2010\n",
      "First request failed\n",
      "Missing COP, 2010\n",
      "Getting all submissions with query 'COP' within subreddit changemyview from 1-1-2010 to 12-31-2010\n",
      "First request failed\n",
      "Missing IPCC, 2010\n",
      "Getting all submissions with query 'IPCC' within subreddit changemyview from 1-1-2010 to 12-31-2010\n",
      "Num submissions: 0 0\n",
      "Saved query submissions to pushshift_output/posts/changemyview/1-1-2010_to_12-31-2010/IPCC.pkl!\n",
      "Missing deforestation, 2010\n",
      "Getting all submissions with query 'deforestation' within subreddit changemyview from 1-1-2010 to 12-31-2010\n",
      "Num submissions: 0 0\n",
      "Saved query submissions to pushshift_output/posts/changemyview/1-1-2010_to_12-31-2010/deforestation.pkl!\n",
      "Missing permafrost, 2010\n",
      "Getting all submissions with query 'permafrost' within subreddit changemyview from 1-1-2010 to 12-31-2010\n",
      "Num submissions: 0 0\n",
      "Saved query submissions to pushshift_output/posts/changemyview/1-1-2010_to_12-31-2010/permafrost.pkl!\n",
      "Missing glacier, 2010\n",
      "Getting all submissions with query 'glacier' within subreddit changemyview from 1-1-2010 to 12-31-2010\n",
      "Num submissions: 0 0\n",
      "Saved query submissions to pushshift_output/posts/changemyview/1-1-2010_to_12-31-2010/glacier.pkl!\n",
      "Missing drought, 2010\n",
      "Getting all submissions with query 'drought' within subreddit changemyview from 1-1-2010 to 12-31-2010\n",
      "Num submissions: 0 0\n",
      "Saved query submissions to pushshift_output/posts/changemyview/1-1-2010_to_12-31-2010/drought.pkl!\n",
      "Missing ecosystem, 2010\n",
      "Getting all submissions with query 'ecosystem' within subreddit changemyview from 1-1-2010 to 12-31-2010\n",
      "Num submissions: 0 0\n",
      "Saved query submissions to pushshift_output/posts/changemyview/1-1-2010_to_12-31-2010/ecosystem.pkl!\n",
      "Missing greenhouse gas, 2010\n",
      "Getting all submissions with query 'greenhouse gas' within subreddit changemyview from 1-1-2010 to 12-31-2010\n",
      "Num submissions: 0 0\n",
      "Saved query submissions to pushshift_output/posts/changemyview/1-1-2010_to_12-31-2010/greenhouse gas.pkl!\n",
      "Missing greenhouse effect, 2010\n",
      "Getting all submissions with query 'greenhouse effect' within subreddit changemyview from 1-1-2010 to 12-31-2010\n",
      "Num submissions: 0 0\n",
      "Saved query submissions to pushshift_output/posts/changemyview/1-1-2010_to_12-31-2010/greenhouse effect.pkl!\n",
      "Missing green new deal, 2010\n",
      "Getting all submissions with query 'green new deal' within subreddit changemyview from 1-1-2010 to 12-31-2010\n",
      "First request failed\n",
      "Missing EPA, 2010\n",
      "Getting all submissions with query 'EPA' within subreddit changemyview from 1-1-2010 to 12-31-2010\n",
      "Num submissions: 0 0\n",
      "Saved query submissions to pushshift_output/posts/changemyview/1-1-2010_to_12-31-2010/EPA.pkl!\n",
      "Missing global warming, 2011\n",
      "Getting all submissions with query 'global warming' within subreddit changemyview from 1-1-2011 to 12-31-2011\n",
      "First request failed\n",
      "Missing climate change, 2011\n",
      "Getting all submissions with query 'climate change' within subreddit changemyview from 1-1-2011 to 12-31-2011\n",
      "First request failed\n",
      "Missing carbon, 2011\n",
      "Getting all submissions with query 'carbon' within subreddit changemyview from 1-1-2011 to 12-31-2011\n",
      "First request failed\n",
      "Missing fossil fuel, 2011\n",
      "Getting all submissions with query 'fossil fuel' within subreddit changemyview from 1-1-2011 to 12-31-2011\n",
      "Num submissions: 0 0\n",
      "Saved query submissions to pushshift_output/posts/changemyview/1-1-2011_to_12-31-2011/fossil fuel.pkl!\n",
      "Missing methane, 2011\n",
      "Getting all submissions with query 'methane' within subreddit changemyview from 1-1-2011 to 12-31-2011\n",
      "First request failed\n",
      "Missing environment, 2011\n",
      "Getting all submissions with query 'environment' within subreddit changemyview from 1-1-2011 to 12-31-2011\n",
      "First request failed\n",
      "Missing co2, 2011\n",
      "Getting all submissions with query 'co2' within subreddit changemyview from 1-1-2011 to 12-31-2011\n",
      "First request failed\n",
      "Missing climate crisis, 2011\n",
      "Getting all submissions with query 'climate crisis' within subreddit changemyview from 1-1-2011 to 12-31-2011\n",
      "First request failed\n",
      "Missing climate emergency, 2011\n",
      "Getting all submissions with query 'climate emergency' within subreddit changemyview from 1-1-2011 to 12-31-2011\n",
      "Num submissions: 0 0\n",
      "Saved query submissions to pushshift_output/posts/changemyview/1-1-2011_to_12-31-2011/climate emergency.pkl!\n",
      "Missing extreme weather, 2011\n",
      "Getting all submissions with query 'extreme weather' within subreddit changemyview from 1-1-2011 to 12-31-2011\n",
      "First request failed\n",
      "Missing 2 degree, 2011\n",
      "Getting all submissions with query '2 degree' within subreddit changemyview from 1-1-2011 to 12-31-2011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num submissions: 0 0\n",
      "Saved query submissions to pushshift_output/posts/changemyview/1-1-2011_to_12-31-2011/2 degree.pkl!\n",
      "Missing sustainable, 2011\n",
      "Getting all submissions with query 'sustainable' within subreddit changemyview from 1-1-2011 to 12-31-2011\n",
      "Num submissions: 0 0\n",
      "Saved query submissions to pushshift_output/posts/changemyview/1-1-2011_to_12-31-2011/sustainable.pkl!\n",
      "Missing clean energy, 2011\n",
      "Getting all submissions with query 'clean energy' within subreddit changemyview from 1-1-2011 to 12-31-2011\n",
      "First request failed\n",
      "Missing renewable, 2011\n",
      "Getting all submissions with query 'renewable' within subreddit changemyview from 1-1-2011 to 12-31-2011\n",
      "Num submissions: 0 0\n",
      "Saved query submissions to pushshift_output/posts/changemyview/1-1-2011_to_12-31-2011/renewable.pkl!\n",
      "Missing cap and trade, 2011\n",
      "Getting all submissions with query 'cap and trade' within subreddit changemyview from 1-1-2011 to 12-31-2011\n",
      "First request failed\n",
      "Missing sea level rise, 2011\n",
      "Getting all submissions with query 'sea level rise' within subreddit changemyview from 1-1-2011 to 12-31-2011\n",
      "First request failed\n",
      "Missing environmental justice, 2011\n",
      "Getting all submissions with query 'environmental justice' within subreddit changemyview from 1-1-2011 to 12-31-2011\n",
      "First request failed\n",
      "Missing climate justice, 2011\n",
      "Getting all submissions with query 'climate justice' within subreddit changemyview from 1-1-2011 to 12-31-2011\n",
      "Num submissions: 0 0\n",
      "Saved query submissions to pushshift_output/posts/changemyview/1-1-2011_to_12-31-2011/climate justice.pkl!\n",
      "Missing COP, 2011\n",
      "Getting all submissions with query 'COP' within subreddit changemyview from 1-1-2011 to 12-31-2011\n",
      "First request failed\n",
      "Missing IPCC, 2011\n",
      "Getting all submissions with query 'IPCC' within subreddit changemyview from 1-1-2011 to 12-31-2011\n",
      "First request failed\n",
      "Missing deforestation, 2011\n",
      "Getting all submissions with query 'deforestation' within subreddit changemyview from 1-1-2011 to 12-31-2011\n",
      "First request failed\n",
      "Missing permafrost, 2011\n",
      "Getting all submissions with query 'permafrost' within subreddit changemyview from 1-1-2011 to 12-31-2011\n",
      "Num submissions: 0 0\n",
      "Saved query submissions to pushshift_output/posts/changemyview/1-1-2011_to_12-31-2011/permafrost.pkl!\n",
      "Missing glacier, 2011\n",
      "Getting all submissions with query 'glacier' within subreddit changemyview from 1-1-2011 to 12-31-2011\n",
      "First request failed\n",
      "Missing drought, 2011\n",
      "Getting all submissions with query 'drought' within subreddit changemyview from 1-1-2011 to 12-31-2011\n",
      "Num submissions: 0 0\n",
      "Saved query submissions to pushshift_output/posts/changemyview/1-1-2011_to_12-31-2011/drought.pkl!\n",
      "Missing ecosystem, 2011\n",
      "Getting all submissions with query 'ecosystem' within subreddit changemyview from 1-1-2011 to 12-31-2011\n",
      "Num submissions: 0 0\n",
      "Saved query submissions to pushshift_output/posts/changemyview/1-1-2011_to_12-31-2011/ecosystem.pkl!\n",
      "Missing greenhouse gas, 2011\n",
      "Getting all submissions with query 'greenhouse gas' within subreddit changemyview from 1-1-2011 to 12-31-2011\n",
      "Num submissions: 0 0\n",
      "Saved query submissions to pushshift_output/posts/changemyview/1-1-2011_to_12-31-2011/greenhouse gas.pkl!\n",
      "Missing greenhouse effect, 2011\n",
      "Getting all submissions with query 'greenhouse effect' within subreddit changemyview from 1-1-2011 to 12-31-2011\n",
      "Num submissions: 0 0\n",
      "Saved query submissions to pushshift_output/posts/changemyview/1-1-2011_to_12-31-2011/greenhouse effect.pkl!\n",
      "Missing green new deal, 2011\n",
      "Getting all submissions with query 'green new deal' within subreddit changemyview from 1-1-2011 to 12-31-2011\n",
      "Num submissions: 0 0\n",
      "Saved query submissions to pushshift_output/posts/changemyview/1-1-2011_to_12-31-2011/green new deal.pkl!\n",
      "Missing EPA, 2011\n",
      "Getting all submissions with query 'EPA' within subreddit changemyview from 1-1-2011 to 12-31-2011\n",
      "Num submissions: 0 0\n",
      "Saved query submissions to pushshift_output/posts/changemyview/1-1-2011_to_12-31-2011/EPA.pkl!\n",
      "Missing global warming, 2012\n",
      "Getting all submissions with query 'global warming' within subreddit changemyview from 1-1-2012 to 12-31-2012\n",
      "First request failed\n",
      "Missing climate change, 2012\n",
      "Getting all submissions with query 'climate change' within subreddit changemyview from 1-1-2012 to 12-31-2012\n",
      "First request failed\n",
      "Missing carbon, 2012\n",
      "Getting all submissions with query 'carbon' within subreddit changemyview from 1-1-2012 to 12-31-2012\n",
      "First request failed\n",
      "Missing fossil fuel, 2012\n",
      "Getting all submissions with query 'fossil fuel' within subreddit changemyview from 1-1-2012 to 12-31-2012\n",
      "Num submissions: 0 0\n",
      "Saved query submissions to pushshift_output/posts/changemyview/1-1-2012_to_12-31-2012/fossil fuel.pkl!\n",
      "Missing methane, 2012\n",
      "Getting all submissions with query 'methane' within subreddit changemyview from 1-1-2012 to 12-31-2012\n",
      "First request failed\n",
      "Missing environment, 2012\n",
      "Getting all submissions with query 'environment' within subreddit changemyview from 1-1-2012 to 12-31-2012\n",
      "First request failed\n",
      "Missing co2, 2012\n",
      "Getting all submissions with query 'co2' within subreddit changemyview from 1-1-2012 to 12-31-2012\n",
      "First request failed\n",
      "Missing climate crisis, 2012\n",
      "Getting all submissions with query 'climate crisis' within subreddit changemyview from 1-1-2012 to 12-31-2012\n",
      "First request failed\n",
      "Missing climate emergency, 2012\n",
      "Getting all submissions with query 'climate emergency' within subreddit changemyview from 1-1-2012 to 12-31-2012\n",
      "First request failed\n",
      "Missing extreme weather, 2012\n",
      "Getting all submissions with query 'extreme weather' within subreddit changemyview from 1-1-2012 to 12-31-2012\n",
      "Num submissions: 0 0\n",
      "Saved query submissions to pushshift_output/posts/changemyview/1-1-2012_to_12-31-2012/extreme weather.pkl!\n",
      "Missing 2 degree, 2012\n",
      "Getting all submissions with query '2 degree' within subreddit changemyview from 1-1-2012 to 12-31-2012\n",
      "First request failed\n",
      "Missing sustainable, 2012\n",
      "Getting all submissions with query 'sustainable' within subreddit changemyview from 1-1-2012 to 12-31-2012\n",
      "First request failed\n",
      "Missing clean energy, 2012\n",
      "Getting all submissions with query 'clean energy' within subreddit changemyview from 1-1-2012 to 12-31-2012\n",
      "First request failed\n",
      "Missing renewable, 2012\n",
      "Getting all submissions with query 'renewable' within subreddit changemyview from 1-1-2012 to 12-31-2012\n",
      "First request failed\n",
      "Missing cap and trade, 2012\n",
      "Getting all submissions with query 'cap and trade' within subreddit changemyview from 1-1-2012 to 12-31-2012\n",
      "First request failed\n",
      "Missing sea level rise, 2012\n",
      "Getting all submissions with query 'sea level rise' within subreddit changemyview from 1-1-2012 to 12-31-2012\n",
      "First request failed\n",
      "Missing environmental justice, 2012\n",
      "Getting all submissions with query 'environmental justice' within subreddit changemyview from 1-1-2012 to 12-31-2012\n",
      "First request failed\n",
      "Missing climate justice, 2012\n",
      "Getting all submissions with query 'climate justice' within subreddit changemyview from 1-1-2012 to 12-31-2012\n",
      "Num submissions: 0 0\n",
      "Saved query submissions to pushshift_output/posts/changemyview/1-1-2012_to_12-31-2012/climate justice.pkl!\n",
      "Missing COP, 2012\n",
      "Getting all submissions with query 'COP' within subreddit changemyview from 1-1-2012 to 12-31-2012\n",
      "First request failed\n",
      "Missing IPCC, 2012\n",
      "Getting all submissions with query 'IPCC' within subreddit changemyview from 1-1-2012 to 12-31-2012\n",
      "First request failed\n",
      "Missing deforestation, 2012\n",
      "Getting all submissions with query 'deforestation' within subreddit changemyview from 1-1-2012 to 12-31-2012\n",
      "First request failed\n",
      "Missing permafrost, 2012\n",
      "Getting all submissions with query 'permafrost' within subreddit changemyview from 1-1-2012 to 12-31-2012\n",
      "First request failed\n",
      "Missing glacier, 2012\n",
      "Getting all submissions with query 'glacier' within subreddit changemyview from 1-1-2012 to 12-31-2012\n",
      "First request failed\n",
      "Missing drought, 2012\n",
      "Getting all submissions with query 'drought' within subreddit changemyview from 1-1-2012 to 12-31-2012\n",
      "Num submissions: 0 0\n",
      "Saved query submissions to pushshift_output/posts/changemyview/1-1-2012_to_12-31-2012/drought.pkl!\n",
      "Missing ecosystem, 2012\n",
      "Getting all submissions with query 'ecosystem' within subreddit changemyview from 1-1-2012 to 12-31-2012\n",
      "First request failed\n",
      "Missing greenhouse gas, 2012\n",
      "Getting all submissions with query 'greenhouse gas' within subreddit changemyview from 1-1-2012 to 12-31-2012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First request failed\n",
      "Missing greenhouse effect, 2012\n",
      "Getting all submissions with query 'greenhouse effect' within subreddit changemyview from 1-1-2012 to 12-31-2012\n",
      "First request failed\n",
      "Missing green new deal, 2012\n",
      "Getting all submissions with query 'green new deal' within subreddit changemyview from 1-1-2012 to 12-31-2012\n",
      "First request failed\n",
      "Missing EPA, 2012\n",
      "Getting all submissions with query 'EPA' within subreddit changemyview from 1-1-2012 to 12-31-2012\n",
      "First request failed\n",
      "Missing global warming, 2013\n",
      "Getting all submissions with query 'global warming' within subreddit changemyview from 1-1-2013 to 12-31-2013\n",
      "Num submissions: 0 0\n",
      "Saved query submissions to pushshift_output/posts/changemyview/1-1-2013_to_12-31-2013/global warming.pkl!\n",
      "Missing climate change, 2013\n",
      "Getting all submissions with query 'climate change' within subreddit changemyview from 1-1-2013 to 12-31-2013\n",
      "First request failed\n",
      "Missing carbon, 2013\n",
      "Getting all submissions with query 'carbon' within subreddit changemyview from 1-1-2013 to 12-31-2013\n",
      "First request failed\n",
      "Missing fossil fuel, 2013\n",
      "Getting all submissions with query 'fossil fuel' within subreddit changemyview from 1-1-2013 to 12-31-2013\n",
      "First request failed\n",
      "Missing methane, 2013\n",
      "Getting all submissions with query 'methane' within subreddit changemyview from 1-1-2013 to 12-31-2013\n",
      "Num submissions: 0 0\n",
      "Saved query submissions to pushshift_output/posts/changemyview/1-1-2013_to_12-31-2013/methane.pkl!\n",
      "Missing environment, 2013\n",
      "Getting all submissions with query 'environment' within subreddit changemyview from 1-1-2013 to 12-31-2013\n",
      "First request failed\n",
      "Missing co2, 2013\n",
      "Getting all submissions with query 'co2' within subreddit changemyview from 1-1-2013 to 12-31-2013\n",
      "First request failed\n",
      "Missing climate crisis, 2013\n",
      "Getting all submissions with query 'climate crisis' within subreddit changemyview from 1-1-2013 to 12-31-2013\n",
      "First request failed\n",
      "Missing climate emergency, 2013\n",
      "Getting all submissions with query 'climate emergency' within subreddit changemyview from 1-1-2013 to 12-31-2013\n",
      "First request failed\n",
      "Missing extreme weather, 2013\n",
      "Getting all submissions with query 'extreme weather' within subreddit changemyview from 1-1-2013 to 12-31-2013\n",
      "Num submissions: 0 0\n",
      "Saved query submissions to pushshift_output/posts/changemyview/1-1-2013_to_12-31-2013/extreme weather.pkl!\n",
      "Missing 2 degree, 2013\n",
      "Getting all submissions with query '2 degree' within subreddit changemyview from 1-1-2013 to 12-31-2013\n",
      "First request failed\n",
      "Missing sustainable, 2013\n",
      "Getting all submissions with query 'sustainable' within subreddit changemyview from 1-1-2013 to 12-31-2013\n",
      "Num submissions: 0 0\n",
      "Saved query submissions to pushshift_output/posts/changemyview/1-1-2013_to_12-31-2013/sustainable.pkl!\n",
      "Missing clean energy, 2013\n",
      "Getting all submissions with query 'clean energy' within subreddit changemyview from 1-1-2013 to 12-31-2013\n",
      "Num submissions: 0 0\n",
      "Saved query submissions to pushshift_output/posts/changemyview/1-1-2013_to_12-31-2013/clean energy.pkl!\n",
      "Missing renewable, 2013\n",
      "Getting all submissions with query 'renewable' within subreddit changemyview from 1-1-2013 to 12-31-2013\n",
      "Num submissions: 0 0\n",
      "Saved query submissions to pushshift_output/posts/changemyview/1-1-2013_to_12-31-2013/renewable.pkl!\n",
      "Missing cap and trade, 2013\n",
      "Getting all submissions with query 'cap and trade' within subreddit changemyview from 1-1-2013 to 12-31-2013\n",
      "Num submissions: 0 0\n",
      "Saved query submissions to pushshift_output/posts/changemyview/1-1-2013_to_12-31-2013/cap and trade.pkl!\n",
      "Missing sea level rise, 2013\n",
      "Getting all submissions with query 'sea level rise' within subreddit changemyview from 1-1-2013 to 12-31-2013\n",
      "Num submissions: 0 0\n",
      "Saved query submissions to pushshift_output/posts/changemyview/1-1-2013_to_12-31-2013/sea level rise.pkl!\n",
      "Missing environmental justice, 2013\n",
      "Getting all submissions with query 'environmental justice' within subreddit changemyview from 1-1-2013 to 12-31-2013\n",
      "Num submissions: 0 0\n",
      "Saved query submissions to pushshift_output/posts/changemyview/1-1-2013_to_12-31-2013/environmental justice.pkl!\n",
      "Missing climate justice, 2013\n",
      "Getting all submissions with query 'climate justice' within subreddit changemyview from 1-1-2013 to 12-31-2013\n",
      "Num submissions: 0 0\n",
      "Saved query submissions to pushshift_output/posts/changemyview/1-1-2013_to_12-31-2013/climate justice.pkl!\n",
      "Missing COP, 2013\n",
      "Getting all submissions with query 'COP' within subreddit changemyview from 1-1-2013 to 12-31-2013\n",
      "Num submissions: 0 0\n",
      "Saved query submissions to pushshift_output/posts/changemyview/1-1-2013_to_12-31-2013/COP.pkl!\n",
      "Missing IPCC, 2013\n",
      "Getting all submissions with query 'IPCC' within subreddit changemyview from 1-1-2013 to 12-31-2013\n",
      "First request failed\n",
      "Missing deforestation, 2013\n",
      "Getting all submissions with query 'deforestation' within subreddit changemyview from 1-1-2013 to 12-31-2013\n",
      "First request failed\n",
      "Missing permafrost, 2013\n",
      "Getting all submissions with query 'permafrost' within subreddit changemyview from 1-1-2013 to 12-31-2013\n",
      "Num submissions: 0 0\n",
      "Saved query submissions to pushshift_output/posts/changemyview/1-1-2013_to_12-31-2013/permafrost.pkl!\n",
      "Missing glacier, 2013\n",
      "Getting all submissions with query 'glacier' within subreddit changemyview from 1-1-2013 to 12-31-2013\n",
      "First request failed\n",
      "Missing drought, 2013\n",
      "Getting all submissions with query 'drought' within subreddit changemyview from 1-1-2013 to 12-31-2013\n",
      "First request failed\n",
      "Missing ecosystem, 2013\n",
      "Getting all submissions with query 'ecosystem' within subreddit changemyview from 1-1-2013 to 12-31-2013\n",
      "First request failed\n",
      "Missing greenhouse gas, 2013\n",
      "Getting all submissions with query 'greenhouse gas' within subreddit changemyview from 1-1-2013 to 12-31-2013\n",
      "First request failed\n",
      "Missing greenhouse effect, 2013\n",
      "Getting all submissions with query 'greenhouse effect' within subreddit changemyview from 1-1-2013 to 12-31-2013\n",
      "First request failed\n",
      "Missing green new deal, 2013\n",
      "Getting all submissions with query 'green new deal' within subreddit changemyview from 1-1-2013 to 12-31-2013\n",
      "First request failed\n",
      "Missing EPA, 2013\n",
      "Getting all submissions with query 'EPA' within subreddit changemyview from 1-1-2013 to 12-31-2013\n",
      "Num submissions: 0 0\n",
      "Saved query submissions to pushshift_output/posts/changemyview/1-1-2013_to_12-31-2013/EPA.pkl!\n",
      "Missing global warming, 2014\n",
      "Getting all submissions with query 'global warming' within subreddit changemyview from 1-1-2014 to 12-31-2014\n",
      "First request failed\n",
      "Missing climate change, 2014\n",
      "Getting all submissions with query 'climate change' within subreddit changemyview from 1-1-2014 to 12-31-2014\n",
      "First request failed\n",
      "Missing carbon, 2014\n",
      "Getting all submissions with query 'carbon' within subreddit changemyview from 1-1-2014 to 12-31-2014\n",
      "First request failed\n",
      "Missing fossil fuel, 2014\n",
      "Getting all submissions with query 'fossil fuel' within subreddit changemyview from 1-1-2014 to 12-31-2014\n",
      "First request failed\n",
      "Missing methane, 2014\n",
      "Getting all submissions with query 'methane' within subreddit changemyview from 1-1-2014 to 12-31-2014\n",
      "First request failed\n",
      "Missing environment, 2014\n",
      "Getting all submissions with query 'environment' within subreddit changemyview from 1-1-2014 to 12-31-2014\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-f759d09e4aca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Missing {}, {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyword\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart_year\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             pushshift_wrapper('1-1-{}'.format(start_year),'12-31-{}'.format(start_year),\n\u001b[0;32m---> 11\u001b[0;31m                               'submission',subreddit='changemyview',query=keyword)\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-2caa3d1e9dbc>\u001b[0m in \u001b[0;36mpushshift_wrapper\u001b[0;34m(after_str, before_str, datatype, subreddit, query, keywords)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 data = getPushshiftDataForSub(subreddit, query, \n\u001b[0;32m---> 30\u001b[0;31m                                               after_str, before_str, datatype)\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0mfailed_requests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubreddit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mafter_str\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbefore_str\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-64aed0d93794>\u001b[0m in \u001b[0;36mgetPushshiftDataForSub\u001b[0;34m(subreddit, query, after_str, before_str, datatype)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;34m'&before='\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbefore_date\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m#print(url)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/nlp/anaconda/main/anaconda3/envs/yiwei-climate/lib/python3.6/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/nlp/anaconda/main/anaconda3/envs/yiwei-climate/lib/python3.6/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/nlp/anaconda/main/anaconda3/envs/yiwei-climate/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    531\u001b[0m         }\n\u001b[1;32m    532\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/nlp/anaconda/main/anaconda3/envs/yiwei-climate/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/nlp/anaconda/main/anaconda3/envs/yiwei-climate/lib/python3.6/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/nlp/anaconda/main/anaconda3/envs/yiwei-climate/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    675\u001b[0m                 \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m             )\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/nlp/anaconda/main/anaconda3/envs/yiwei-climate/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    424\u001b[0m                     \u001b[0;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m                     \u001b[0;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/nlp/anaconda/main/anaconda3/envs/yiwei-climate/lib/python3.6/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;32m/u/nlp/anaconda/main/anaconda3/envs/yiwei-climate/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    419\u001b[0m                 \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/nlp/anaconda/main/anaconda3/envs/yiwei-climate/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1329\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1331\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1332\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/nlp/anaconda/main/anaconda3/envs/yiwei-climate/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mUnknownProtocol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_headers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebuglevel\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/nlp/anaconda/main/anaconda3/envs/yiwei-climate/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mparse_headers\u001b[0;34m(fp, _class)\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"header line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Collect all posts w/ climate change keyword from CMV  \n",
    "\n",
    "for start_year in range(2010,2015,1):\n",
    "    end_year = start_year+1\n",
    "    for keyword in KEYWORDS_LONG:\n",
    "        if not os.path.exists(os.path.join('pushshift_output','posts','changemyview'\n",
    "                                           '1-1-{}_to_12-31-{}'.format(start_year,start_year),\n",
    "                                           '{}.pkl'.format(keyword))):\n",
    "            print(\"Missing {}, {}\".format(keyword,start_year))\n",
    "            pushshift_wrapper('1-1-{}'.format(start_year),'12-31-{}'.format(start_year),\n",
    "                              'submission',subreddit='changemyview',query=keyword)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "out = getPushshiftDataForSub('changemyview', 'the', '1-1-{}'.format(start_year),\n",
    "                       '12-31-{}'.format(start_year), 'submission')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1-1-2010'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'1-1-{}'.format(start_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for start_year in range(2015,2021,1):\n",
    "#     end_year = start_year+1\n",
    "#     pushshift_wrapper('1-1-{}'.format(start_year),'12-31-{}'.format(start_year),'submission',\n",
    "#                       query=None,keywords=keywords_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Get all comments attached to a post"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## PRAW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Get IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "419100"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_with_comments_ids = pickle.load(open('output/posts_with_comments_ids.pkl','rb'))\n",
    "print(len(posts_with_comments_ids))\n",
    "sub_ids_to_fetch = list(posts_with_comments_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# with open('output/comment_ids_per_post.tsv','w') as f:\n",
    "#     f.write(\"{}\\t{}\\n\".format('post_id','comment_ids'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def praw_get_comments(sub_id):\n",
    "    try:\n",
    "        post = reddit.submission(id=sub_id)\n",
    "        post_author = post.author\n",
    "        post_title = post.title\n",
    "        post_comms = list(post.__dict__['_comments_by_id'].keys())\n",
    "        #print(len(post_comms))\n",
    "        comments_per_post[sub_id] = post_comms\n",
    "\n",
    "        with open('output/comment_ids_per_post.tsv','a') as f:\n",
    "            f.write(\"{}\\t{}\\n\".format(sub_id,','.join(post_comms)))\n",
    "    except Forbidden:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175000\n",
      "176000\n",
      "177000\n",
      "178000\n",
      "179000\n",
      "180000\n",
      "181000\n",
      "182000\n",
      "183000\n",
      "184000\n",
      "185000\n",
      "186000\n",
      "187000\n",
      "188000\n",
      "189000\n",
      "190000\n",
      "191000\n",
      "192000\n",
      "193000\n",
      "194000\n",
      "195000\n",
      "196000\n",
      "197000\n",
      "198000\n",
      "199000\n",
      "200000\n",
      "201000\n",
      "202000\n",
      "203000\n",
      "204000\n",
      "205000\n",
      "206000\n",
      "207000\n",
      "208000\n",
      "209000\n",
      "210000\n",
      "211000\n",
      "212000\n",
      "213000\n",
      "214000\n",
      "215000\n",
      "216000\n",
      "217000\n",
      "218000\n",
      "219000\n",
      "220000\n",
      "221000\n",
      "222000\n",
      "223000\n",
      "224000\n",
      "225000\n",
      "226000\n",
      "227000\n",
      "228000\n",
      "229000\n",
      "230000\n",
      "231000\n",
      "232000\n",
      "233000\n",
      "234000\n",
      "235000\n",
      "236000\n",
      "237000\n",
      "238000\n",
      "239000\n",
      "240000\n",
      "241000\n",
      "242000\n",
      "243000\n",
      "244000\n",
      "245000\n",
      "246000\n",
      "247000\n",
      "248000\n",
      "249000\n",
      "250000\n",
      "251000\n",
      "252000\n",
      "253000\n",
      "254000\n",
      "255000\n",
      "256000\n",
      "257000\n",
      "258000\n",
      "259000\n",
      "260000\n",
      "261000\n",
      "262000\n",
      "263000\n",
      "264000\n",
      "265000\n",
      "266000\n",
      "267000\n",
      "268000\n",
      "269000\n",
      "270000\n",
      "271000\n",
      "272000\n",
      "273000\n",
      "274000\n",
      "275000\n",
      "276000\n",
      "277000\n",
      "278000\n",
      "279000\n",
      "280000\n",
      "281000\n",
      "282000\n",
      "283000\n",
      "284000\n",
      "285000\n",
      "286000\n",
      "287000\n",
      "288000\n",
      "289000\n",
      "290000\n",
      "291000\n",
      "292000\n",
      "293000\n",
      "294000\n",
      "295000\n",
      "296000\n",
      "297000\n",
      "298000\n",
      "299000\n",
      "300000\n",
      "301000\n",
      "302000\n",
      "303000\n",
      "304000\n",
      "305000\n",
      "306000\n",
      "307000\n",
      "308000\n",
      "309000\n",
      "310000\n",
      "311000\n",
      "312000\n",
      "313000\n",
      "314000\n",
      "315000\n",
      "316000\n",
      "317000\n",
      "318000\n",
      "319000\n",
      "320000\n",
      "321000\n",
      "322000\n",
      "323000\n",
      "324000\n",
      "325000\n",
      "326000\n",
      "327000\n",
      "328000\n",
      "329000\n",
      "330000\n",
      "331000\n",
      "332000\n",
      "333000\n",
      "334000\n",
      "335000\n",
      "336000\n",
      "337000\n",
      "338000\n",
      "339000\n",
      "340000\n",
      "341000\n",
      "342000\n",
      "343000\n",
      "344000\n",
      "345000\n",
      "346000\n",
      "347000\n",
      "348000\n",
      "349000\n",
      "350000\n",
      "351000\n",
      "352000\n",
      "353000\n",
      "354000\n",
      "355000\n",
      "356000\n",
      "357000\n",
      "358000\n",
      "359000\n",
      "360000\n",
      "361000\n",
      "362000\n",
      "363000\n",
      "364000\n",
      "365000\n",
      "366000\n",
      "367000\n",
      "368000\n",
      "369000\n",
      "370000\n",
      "371000\n",
      "372000\n",
      "373000\n",
      "374000\n",
      "375000\n",
      "376000\n",
      "377000\n",
      "378000\n",
      "379000\n",
      "380000\n",
      "381000\n",
      "382000\n",
      "383000\n",
      "384000\n",
      "385000\n",
      "386000\n",
      "387000\n",
      "388000\n",
      "389000\n",
      "390000\n",
      "391000\n",
      "392000\n",
      "393000\n",
      "394000\n",
      "395000\n",
      "396000\n",
      "397000\n",
      "398000\n",
      "399000\n",
      "400000\n",
      "401000\n",
      "402000\n",
      "403000\n",
      "404000\n",
      "405000\n",
      "406000\n",
      "407000\n",
      "408000\n",
      "409000\n",
      "410000\n",
      "411000\n",
      "412000\n",
      "413000\n",
      "414000\n",
      "415000\n",
      "416000\n",
      "417000\n",
      "418000\n",
      "419000\n"
     ]
    }
   ],
   "source": [
    "for ix_sub_id in range(174623,len(sub_ids_to_fetch)):\n",
    "    sub_id = sub_ids_to_fetch[ix_sub_id]\n",
    "    praw_get_comments(sub_id)\n",
    "    \n",
    "    if ix_sub_id % 1000 == 0:\n",
    "        print(ix_sub_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(174623, '92efdf')"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix_sub_id,sub_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11720"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comments_per_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>comment_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anbg0</td>\n",
       "      <td>t1_c0ignhg,t1_c0ignz0,t1_c0igq3n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apn8b</td>\n",
       "      <td>t1_c0irhej,t1_c0is8sw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aprgq</td>\n",
       "      <td>t1_c0isfnb,t1_c0is90g,t1_c0iscd2,t1_c0isbol,t1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aprgv</td>\n",
       "      <td>t1_c0is3y4,t1_c0ism1k,t1_c0isyft,t1_c0isvkx,t1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aprie</td>\n",
       "      <td>t1_c0is4by,t1_c0islml,t1_c0ismfv,t1_c0isk7q,t1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403412</th>\n",
       "      <td>3yuldj</td>\n",
       "      <td>t1_cygrqj0,t1_cygrhs5,t1_cygtcrx,t1_cygtrvf,t1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403413</th>\n",
       "      <td>3yulsl</td>\n",
       "      <td>t1_cylxj3h,t1_cygqso3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403414</th>\n",
       "      <td>3yup0j</td>\n",
       "      <td>t1_cyhjhnw,t1_cylxiyc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403415</th>\n",
       "      <td>3yuytd</td>\n",
       "      <td>t1_cygu9uo,t1_cygx6g5,t1_cyhpqys,t1_cygxgig,t1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403416</th>\n",
       "      <td>3yve0p</td>\n",
       "      <td>t1_cyh9a2i</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>403417 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       post_id                                        comment_ids\n",
       "0        anbg0                   t1_c0ignhg,t1_c0ignz0,t1_c0igq3n\n",
       "1        apn8b                              t1_c0irhej,t1_c0is8sw\n",
       "2        aprgq  t1_c0isfnb,t1_c0is90g,t1_c0iscd2,t1_c0isbol,t1...\n",
       "3        aprgv  t1_c0is3y4,t1_c0ism1k,t1_c0isyft,t1_c0isvkx,t1...\n",
       "4        aprie  t1_c0is4by,t1_c0islml,t1_c0ismfv,t1_c0isk7q,t1...\n",
       "...        ...                                                ...\n",
       "403412  3yuldj  t1_cygrqj0,t1_cygrhs5,t1_cygtcrx,t1_cygtrvf,t1...\n",
       "403413  3yulsl                              t1_cylxj3h,t1_cygqso3\n",
       "403414  3yup0j                              t1_cyhjhnw,t1_cylxiyc\n",
       "403415  3yuytd  t1_cygu9uo,t1_cygx6g5,t1_cyhpqys,t1_cygxgig,t1...\n",
       "403416  3yve0p                                         t1_cyh9a2i\n",
       "\n",
       "[403417 rows x 2 columns]"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('output/comment_ids_per_post.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Get text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Personally I am more concerned about the fact that methane is an extremely effective greenhouse gas.  '"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment = reddit.comment(\"c0st842\")\n",
    "comment.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "comment_ids_per_post = pd.read_csv('output/comment_ids_per_post.tsv',sep='\\t')\n",
    "comment_ids = comment_ids_per_post['comment_ids']\n",
    "all_comment_ids = [x.split(',') for x in comment_ids]\n",
    "all_comment_ids = [item for sublist in all_comment_ids for item in sublist]\n",
    "unique_comment_ids = set(all_comment_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(len(all_comment_ids),len(unique_comment_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Dataframe of \n",
    "# comment_id | text\n",
    "\n",
    "with open('output/text_per_comment.tsv','w') as f:\n",
    "    f.write('{}\\t{}\\n'.format('comment_id','text'))\n",
    "    \n",
    "unique_comment_ids = list(unique_comment_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for c_id_index in range(len(unique_comment_ids)):\n",
    "    c_id = unique_comment_ids[c_id_index]\n",
    "    comm = reddit.comment(c_id)\n",
    "    comment_body = strip_whitespace(comm.body)\n",
    "    \n",
    "    with open('output/text_per_comment.tsv','a') as f:\n",
    "        f.write('{}\\t{}\\n'.format(c_id,comment_body))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
